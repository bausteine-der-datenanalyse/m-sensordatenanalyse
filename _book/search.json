[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bausteine Computergestützter Datenanalyse",
    "section": "",
    "text": "Anwendungsbaustein Sensordatenanalyse\n\n\n\n\n\n\n\n\n\n\nBausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Anwendungsbaustein Sensordatenanalyse von Maik Poetzsch ist lizensiert unter CC BY 4.0. Das Werk ist abrufbar auf GitHub. Ausgenommen von der Lizenz sind alle Logos Dritter und anders gekennzeichneten Inhalte. 2025\n\n\n\nZitiervorschlag\nArnold, Lukas, Simone Arnold, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2025. „Bausteine Computergestützter Datenanalyse. Anwendungsbaustein Sensordatenanalyse. https://github.com/bausteine-der-datenanalyse/a-sensordatenanalyse.\nBibTeX-Vorlage\n@misc{BCD-a-sensordatenanalyse-2025,\n title={Bausteine Computergestützter Datenanalyse. Anwendungsbaustein Sensordatenanalyse},\n author={Arnold, Lukas and Arnold, Simone and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},\n year={2025},\n url={https://github.com/bausteine-der-datenanalyse/a-sensordatenanalyse}} \n\n\n\nVoraussetzungen\nDie Bearbeitungszeit dieses Bausteins beträgt circa Platzhalter. Für die Bearbeitung dieses Bausteins werden folgende Bausteine vorausgesetzt und die genannten Bibliotheken verwendet:\n\n…\n\nQuerverweis auf:\n\n…\n\nIm Baustein werden folgende Daten verwendet:\n\n\nLernziele\nIn diesen Baustein lernen Sie …",
    "crumbs": [
      "Anwendungsbaustein Sensordatenanalyse"
    ]
  },
  {
    "objectID": "skript/einleitung.html",
    "href": "skript/einleitung.html",
    "title": "1  Das Prinzip von Messungen",
    "section": "",
    "text": "1.1 Messung\nIn diesem Baustein werden die folgenden Module verwendet:\nPhysikalische Größen werden mit der Hilfe von Messgeräten bestimmt. Diese ordnen der tatsächlichen Merkmalsausprägung eine numerische Entsprechung relativ zu einem Bezugssystem zu.\nEin Beispiel: “Johanna ist am Messbrett 173 Zentimeter groß.”\nMesswerte sind aus verschiedenen Gründen Annäherungen an den wahren Wert der zugrundeliegenden physikalischen Größe. Zum einen variiert die Größe eines Menschen im Tagesverlauf. Zum anderen ist das Messergebnis auch ein Ergebnis der verwendeten Skala. Wäre die Messung im imperialen Messsystem erfolgt, wäre Johannas Größe mit 68 Zoll bestimmt worden, was 172,72 Zentimetern entspricht.\nDas Messergebnis ist also keine exakte Entsprechung der tatsächlichen Merkmalsausprägung. Ein bekanntes Beispiel für die mit dem Messvorgang verbundene Unsicherheit ist das Küstenlinienparadox: Das Ergebnis der Vermessung unregelmäßiger Küstenlinien wird umso größer, je kleiner die Messabschnitte gewählt werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#messreihen",
    "href": "skript/einleitung.html#messreihen",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.2 Messreihen",
    "text": "1.2 Messreihen\nUm die Unsicherheit einer Messung zu verringern, kann man einen Messwert in Form einer Messreihe wiederholt aufnehmen. Die (erste) beste Schätzung der Messgröße bietet der arithmetische Mittelwert der Messreihe.\nDer arithmetische Mittelwert einer Messreihe \\(\\bar{x}\\) ist die Summe aller Einzelmesswerte dividiert durch die Anzahl der Messwerte \\(N\\).\n\\[\n\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i\n\\]\nMit Hilfe des arithmetischen Mittelwerts kann eine Aussage über die Streuung der Messwerte und die Präzision der Messung getroffen werden. Dazu werden die Varianz und die Standardabweichung der Messreihe berechnet.\n\nVarianzStandardabweichung\n\n\nDie Varianz ist der Mittelwert der quadrierten Abweichungen vom Mittelwert.\n\\[\n\\text{Var}(x_i) = \\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x})^2\n\\]\nHier könnte statt \\(\\text{Var}(x_i)\\) auch \\(s^{2}\\) geschrieben werden.\n\n\nDie Quadratwurzel der Varianz wird als Standardabweichung bezeichnet. Diese hat den Vorteil, dass sie in der Einheit der Messwerte vorliegt und dadurch leichter zu interpretieren ist. Die Standardabweichung \\(s\\) wird so berechnet:\n\\[\ns_{N} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x})^2}\n\\]\nFür Stichproben wird die Stichprobenvarianz verwendet. Für die Standardabweichung einer Stichprobe gilt:\n\\[\ns_{N-1} = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N}(x_i - \\bar{x})^2}\n\\]\n\n\n\n\n\n\n\n\n\nHinweis 1.1: Standardabweichung und Varianz in der Grundgesamtheit\n\n\n\nIn der Stochastik werden Formeln häufig auch mit griechischen Buchstaben geschrieben, wenn Sie sich statt auf eine Stichprobe auf die Grundgesamtheit beziehen.\nDer Mittelwert in der Grundgesamtheit wird auch Erwartungswert genannt und mit dem griechischen Buchstaben \\(\\mu\\) (My) dargestellt. Die Standardabweichung des Erwartungswerts wird mit \\(\\sigma\\) (Sigma) gekennzeichnet. \\[\n\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\mu)^2}\n\\]\n\n\nMit Hilfe der Standardabweichung kann der Standardfehler der Messung bestimmt werden. Der Standardfehler ist ein Maß dafür, wie genau sich der arithmetische Mittelwert der Stichprobe an den tatsächlichen Mittelwert der Grundgesamtheit, den Erwartungswert, annähert (dazu gleich mehr) und wird auch Stichprobenfehler genannt. Der Standardfehler wird aus der Standardabweichung einer Messung und der Wurzel der Stichprobengröße berechnet. Da die Varianz in der Grundgesamtheit in der Regel unbekannt ist, wird der Standardfehler mit der Stichprobenvarianz geschätzt.\n\\[\n\\sigma_{\\bar{x}} ~ = ~ \\frac{s}{\\sqrt{N}}\n\\]\nDer Standardfehler wird umso kleiner (die Messung umso präziser), je kleiner die Varianz in der Grundgesamtheit und je größer der Stichprobenumfang ist.\nDies lässt sich mit einem simulierten Würfelexperiment verdeutlichen. Bei einem idealen, fairen Würfel kommt jede Augenzahl gleich oft vor. Der Erwartungswert eines sechsseitigen Würfels ist:\n\\[\n\\frac{1}{6} \\sum_{i=1}^{i=6}(x_i) ~ = ~ 3,5\n\\]\nDie Standardabweichung eines fairen, sechsseitigen Würfels beträgt:\n\\[\n\\sqrt{\\frac{1}{6} \\sum_{i=1}^{i=6}(x_i - 3,5)^2} ~ \\approx ~ 1,71\n\\]\nDa die Varianz in der Grundgesamtheit bekannt ist, hängt der Standardfehler des Mittelwerts eines fairen Würfels allein von der Stichprobengröße ab.\n\nExperiment Verteilungskenngrößen\nIm simulierten Experiment würfeln 100 Personen jeweils 3, 10 und 50 Mal und bilden den Mittelwert der Augen. Weil ein fairer Würfel simuliert wird, kann der Standardfehler mit der Standardabweichung der Grundgesamtheit berechnet werden.\n\nErgebnissegrafische DarstellungCode\n\n\n\n\nWürfe pro Person: 3             Stichprobengröße: 300\nkleinster Mittelwert: 1.00      größter Mittelwert: 6.00\nStichprobenmittelwert: 3.57     Standardfehler: 0.10\n\nWürfe pro Person: 10            Stichprobengröße: 1000\nkleinster Mittelwert: 1.70      größter Mittelwert: 4.60\nStichprobenmittelwert: 3.49     Standardfehler: 0.05\n\nWürfe pro Person: 50            Stichprobengröße: 5000\nkleinster Mittelwert: 2.98      größter Mittelwert: 4.36\nStichprobenmittelwert: 3.50     Standardfehler: 0.02\n\n\n\nMit zunehmender Anzahl an Würfen nähern sich Minimum und Maximum der individuellen Durchschnittswerte sowie der Stichprobenmittelwert dem Erwartungswert an.\nHinweis: Da das Skript dynamisch generiert wird, wurden die Zufallszahlen von einem festgelegten Startwert aus erzeugt.\n\n\nDie Häufigkeit der individuellen Mittelwerte ist in den folgenden Histogrammen dargestellt.\n\n\n\n\n\n\n\n\n\n\n\nBerechnung\n\npersonen = 100\nstandardabweichung_grundgesamtheit = np.arange(1, 7).std(ddof = 0)\nseed = 1\n\n# 3 Würfe\nwürfe = 3\n\n## Personen stehen in den Zeilen (axis = 0), Würfe in den Spalten (axis = 1)\naugen3 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen3.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen3.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen3.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen3.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\n# 10 Würfe\nwürfe = 10\n\n## Personen stehen in den Zeilen (axis = 0), Würfe in den Spalten (axis = 1)\naugen10 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen10.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen10.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen10.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen10.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\n# 50 Würfe\nwürfe = 50\n\n## Personen stehen in den Zeilen (axis = 1), Würfe in den Spalten (axis = 1)\naugen50 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen50.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen50.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen50.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen50.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\nDarstellung\n\npersonen = 100\nstandardabweichung_grundgesamtheit = np.arange(1, 7).std(ddof = 0)\nseed = 1\n\n# 3 Würfe\nwürfe = 3\naugen3 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# 10 Würfe\nwürfe = 10\naugen10 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# 50 Würfe\nwürfe = 50\naugen50 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# plotten\nbins = 10\n\n# 3 Würfe\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey = True)\n\nax1.hist(augen3.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax1.set_xlim(1, 6)\nax1.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black', label = 'Erwartungswert')\nax1.set_ylabel('mittleres Würfelergebnis')\nax1.set_ylabel('Häufigkeit Mittelwert')\nax1.set_title(\"3 Würfe pro Person\")\nax1.legend(loc = 'lower left', bbox_to_anchor = (0, -0.2))\n\n# 10 Würfe\nax2.hist(augen10.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax2.set_xlim(1, 6)\nax2.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black')\nax2.set_ylabel('mittleres Würfelergebnis')\nax2.set_title(\"10 Würfe pro Person\")\n\n# 30 Würfe\nax3.hist(augen50.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax3.set_xlim(1, 6)\nax3.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black')\nax3.set_ylabel('mittleres Würfelergebnis')\nax3.set_title(\"30 Würfe pro Person\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nAufgabe Verteilungskenngrößen\nIm Datensatz ToothGrowth.csv ist eine Messreihe zur Länge zahnbildender Zellen bei Meerschweinchen gespeichert. Die Tiere erhielten Vitamin C direkt (VC) oder in Form von Orangensaft (OJ) in unterschiedlichen Dosen.\n\n\n\n\n\ndateipfad = \"01-daten/ToothGrowth.csv\"\nmeerschweinchen = pd.read_csv(filepath_or_buffer = dateipfad, sep = ',', header = 0, \\\n  names = ['ID', 'len', 'supp', 'dose'], dtype = {'ID': 'int', 'len': 'float', 'dose': 'float', 'supp': 'category'})\n\n\n\nCode-Block 1.1\n\n\n\nCrampton, E. W. 1947. „THE GROWTH OF THE ODONTOBLASTS OF THE INCISOR TOOTH AS A CRITERION OF THE VITAMIN C INTAKE OF THE GUINEA PIG“. The Journal of Nutrition 33 (5): 491–504. https://doi.org/10.1093/jn/33.5.491\nDer Datensatz kann in R mit dem Befehl “ToothGrowth” aufgerufen werden.\n\n\n\n\n\n\n\n\n\n\n \nBerechnen Sie den arithmetischen Mittelwert, die Varianz, die Standardabweichung und den Stichprobenfehler der Messreihe zur Zahnlänge (len). Verwenden Sie dazu die vorgestellten Formeln.\nDas Ergebnis könnte so aussehen:\n\n\nN: 60\narithmetisches Mittel: 18.81\nStichprobenfehler: 0.99\nStichprobenvarianz: 58.51\nStandardabweichung: 7.65\n\n\n\n\n\n\n\n\nTipp 1.1: Musterlösung Verteilungskenngrößen\n\n\n\n\n\n\ndef verteilungskennwerte(x, output = True):\n\n  # Anzahl Messwerte bestimmen\n  N = len(x)\n\n  # arithmetisches Mittel bestimmen\n  mittelwert = sum(x) / N\n\n  # Stichprobenvarianz bestimmen\n  stichprobenvarianz = sum((x - mittelwert) ** 2) / (N - 1)\n\n  # Standardabweichung bestimmen\n  standardabweichung = stichprobenvarianz ** (1/2)\n\n  # Stichprobenfehler bestimmen\n  stichprobenfehler = standardabweichung / (N ** (1/2))\n\n  # Ausgabe\n  if output: # output = True\n    print(f\"N: {N}\\n\",\n          f\"arithmetisches Mittel: {mittelwert:.2f}\\n\",\n          f\"Stichprobenfehler: {stichprobenfehler:.2f}\\n\",\n          f\"Stichprobenvarianz: {stichprobenvarianz:.2f}\\n\",\n          f\"Standardabweichung: {standardabweichung:.2f}\",\n          sep = '')\n\n  else: # output = False\n    return N, mittelwert, stichprobenfehler, stichprobenvarianz, standardabweichung\n\nverteilungskennwerte(meerschweinchen['len'])\n\n\n\n\nDie Module NumPy und Pandas verfügen über eigene Funktionen zur Berechnung der Varianz und der Standardabweichung (siehe folgendes Beispiel).\n\n\n\n\n\n\nBeispiel 1.1: Varianz und Standardabweichung mit NumPy und Pandas\n\n\n\n\n\nDie Varianz und Standardabweichung werden mit den Funktion np.var() und np.std() bzw. den Methoden pd.var() und pd.std() berechnet. Der Parameter ddof (delta degrees of freedom) steuert, welcher Nenner zur Berechnung der Varianz verwendet wird in der Form N - ddof. Während der Standardwert in NumPy 0 ist, berechnet Pandas mit dem Standardwert ddof=1 die Stichprobenvarianz.\n\nprint(\"Varianz:\")\nprint(f\"NumPy:\\t{np.var(meerschweinchen['len']):.2f}\")\nprint(f\"Pandas:\\t{meerschweinchen['len'].var():.2f}\")\n\nprint(\"\\nStandardabweichung:\")\nprint(f\"NumPy:\\t{np.std(meerschweinchen['len']):.2f}\")\nprint(f\"Pandas:\\t{meerschweinchen['len'].std():.2f}\")\n\nVarianz:\nNumPy:  57.54\nPandas: 58.51\n\nStandardabweichung:\nNumPy:  7.59\nPandas: 7.65",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#die-ideale-messung",
    "href": "skript/einleitung.html#die-ideale-messung",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.2 Die ideale Messung",
    "text": "1.2 Die ideale Messung\n\n\n\n\n\n\nDefinition 1.2: ideale Messung\n\n\n\n\nDie ideale Messung ist eine direkte Messung oder der gesuchte Wert hängt linear (direkt?!) vom gemessenen Wert ab.\nDie ideale Messung ist genau und präzise.\n\n\n\n\nDirekte und indirekte Messung\nBei einer direkten Messung wird die Messgröße durch den unmittelbaren Vergleich mit einem Normal oder einem genormten Bezugssystem gewonnen.\n\n\n\n\n\n\n\n\n\nBalkenwaage\n\n\n\n\n\n\n\nZollstock\n\n\n\n\n\n\nAbbildung 1.2: Direkte Messung\n\n\n\nGliedermaßstäbe von Fst76 ist lizensiert unter CC-BY-SA 3.0 und ist abrufbar auf Wikimedia. 2014\n\n \nBei einer indirekten Messung wird die Messgröße auf eine andere pyhsikalische Größe zurückgeführt.\n\n\n\n\n\n\n\n\n\nFederwaage\n\n\n\n\n\n\n\nLaserentfernungsmessung\n\n\n\n\n\n\nAbbildung 1.3: Indirekte Messung\n\n\n\nSpring scale von Amada44 steht unter der Lizenz CC-BY-SA-3.0 unported und ist abrufbar auf Wikimedia. 2016\nObserve the Moon wurde von der NASA veröffentlicht und ist abrufbar unter nasa.gov. 2010\n\n\n\nGenauigkeit und Präzision (gehört zu linearer Regression)\nDie Genauigkeit\nVerzerrung (Bias): https://de.wikipedia.org/wiki/Verzerrung_einer_Sch%C3%A4tzfunktion quantifiziert das systematische Über- oder Unterschätzen der Schätzfunktion\nStreuung und Normalverteilung… Stichprobenfehler.\nStichprobenfehler der Meerschweinchenmessung bestimmen Alternativ: mit Würfeldaten simulieren. Erwartungswert eines W6 = 3,5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#normalverteilung",
    "href": "skript/einleitung.html#normalverteilung",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.2 Normalverteilung",
    "text": "1.2 Normalverteilung\nHistogramm und Standardabweichung\nDer Meerschweinchen-Datensatz ist nicht gleichverteilt (die Gruppengrößen sind gleich und die Länge nähert sich einem natürlichen Maximum an.)\n\nmeerschweinchen['len'].plot(kind = 'hist', bins = 7)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html",
    "href": "skript/hooke.html",
    "title": "2  Messreihe Hooke’sches Gesetz",
    "section": "",
    "text": "Deskriptive Statistik\nDas Hooke’sche Gesetz, benannt nach dem englischen Wissenschaftler Robert Hooke, beschreibt die Beziehung zwischen der Kraft \\(F\\) und der Längenänderung \\(\\Delta{x}\\) einer Feder durch die Gleichung \\(F = k \\times \\Delta{x}\\), wobei \\(k\\) die Federkonstante ist. Die Federkonstante ist eine grundlegende Eigenschaft elastischer Materialien und gibt an, wie viel Kraft erforderlich ist, um eine Feder um eine bestimmte Läange zu dehnen oder zu komprimieren. Das Hooke’sche Gesetz besagt, dass die Deformation eines elastischen Körpers proportional zur aufgebrachten Kraft ist, solange die Feder nicht über den elastischen Bereich hinaus gedehnt oder gestaucht wird.\nIn einem Experiment wurde das Hooke’sche Gesetz experimentell überprüft.\nDie Messreihe liegt in Form einer CSV-Datei unter dem Pfad “01-daten/hooke_data.csv” vor. Die Datei kann direkt mit Python oder mit den Modulen NumPy und Pandas eingelesen werden.\nNach dem Einlesen sollte man sich einen Überblick über die Daten verschaffen. Dafür eignet sich besonders das Modul Pandas. Mit den Methoden pd.DataFrame.head() und pd.DataFrame.tail() kann schnell ein Ausschnitt der Daten betrachtet werden.\nprint(hooke.head(), \"\\n\")\nprint(hooke.tail())\n\n   no  mass  distance\n0   0   705    153.29\n1   1   705    152.74\n2   2   705    153.27\n3   3   705    152.81\n4   4   705    152.77 \n\n      no  mass  distance\n109  109     0    173.70\n110  110     0    173.44\n111  111     0    173.75\n112  112     0    173.30\n113  113     0    200.00\nDie Methode pd.DataFrame.describe() erstellt die deskriptive Statistik für den Datensatz. Diese ist in diesem Fall jedoch noch nicht sonderlich nützlich. Die Spalte ‘no’ enthält lediglich eine laufende Versuchsnummer, die Spalte ‘mass’ enhält verschiedene Gewichte.\nhooke.describe()\n\n\n\n\n\n\n\n\nno\nmass\ndistance\n\n\n\n\ncount\n114.000000\n114.000000\n114.000000\n\n\nmean\n56.561404\n394.921053\n162.301754\n\n\nstd\n33.131552\n226.237605\n7.483767\n\n\nmin\n0.000000\n0.000000\n152.740000\n\n\n25%\n28.250000\n201.000000\n156.622500\n\n\n50%\n56.500000\n452.000000\n160.720000\n\n\n75%\n84.750000\n605.000000\n167.767500\n\n\nmax\n113.000000\n705.000000\n200.000000\nSinnvoller ist eine nach dem verwendeten Gewicht aufgeteilte beschreibende Statistik der gemessenen Ausdehnung. Dafür kann die Pandas-Methode pd.DataFrame.groupby() verwendet werden. So kann für jedes der gemessenen Gewichte der arithmethische Mittelwert und die Standardabweichung abgelesen werden.\nhooke.groupby(by = 'mass')['distance'].describe()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nmass\n\n\n\n\n\n\n\n\n\n\n\n\n0\n12.0\n175.828333\n7.620157\n173.27\n173.3150\n173.570\n174.1125\n200.00\n\n\n100\n11.0\n171.044545\n0.985833\n170.15\n170.3650\n170.800\n171.2400\n173.56\n\n\n201\n11.0\n167.791818\n0.296305\n167.26\n167.7200\n167.780\n167.9750\n168.19\n\n\n301\n10.0\n163.710000\n1.660977\n161.60\n162.0575\n163.825\n165.3250\n165.86\n\n\n401\n10.0\n161.967000\n0.313229\n161.42\n161.8450\n161.915\n162.0250\n162.48\n\n\n452\n10.0\n160.713000\n0.627854\n159.98\n160.4575\n160.555\n160.7400\n161.83\n\n\n503\n10.0\n159.314000\n0.781099\n158.43\n158.6400\n159.220\n159.9650\n160.61\n\n\n554\n10.0\n157.547000\n0.523791\n156.92\n157.2075\n157.435\n157.7100\n158.60\n\n\n605\n10.0\n156.142000\n0.354206\n155.62\n156.0700\n156.080\n156.2075\n156.84\n\n\n655\n11.0\n154.022727\n0.224414\n153.72\n153.8800\n153.920\n154.2400\n154.35\n\n\n705\n9.0\n153.008889\n0.241425\n152.74\n152.8100\n152.910\n153.2700\n153.29\nBereits an dieser Stelle könnte die hohe Standardabweichung in der Messreihe mit 0 Gramm auffallen. Leichter ist es jedoch in der grafischen Betrachtung.\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = \"Messreihe Hooke`sches Gesetz\", ylabel = 'Abstand in cm', xlabel = 'Gewicht in Gramm')\nGrafisch fällt der Messwert von 200 cm für das Gewicht 0 Gramm als stark von den übrigen Messwerten abweichend auf.\nDie Messwerte für das Gewicht 0 Gramm sollen näher betrachtet werden. Dafür werden die Messwerte sowohl absolut, als auch standardisiert in Einheiten der Standardabweichung (z-Werten) ausgedrückt ausgegeben.\ngewicht = 0\n\nz_values = hooke[hooke['mass'] == gewicht].loc[: , 'distance'].apply(lambda x: (x - hooke[hooke['mass'] == gewicht].loc[: , 'distance'].mean()) /  hooke[hooke['mass'] == gewicht].loc[: , 'distance'].std())\nz_values.name = 'z-values'\n\nprint(pd.concat([hooke[hooke['mass'] == gewicht], z_values], axis = 1))\n\n      no  mass  distance  z-values\n102  102     0    173.32 -0.329171\n103  103     0    174.11 -0.225498\n104  104     0    173.42 -0.316048\n105  105     0    174.12 -0.224186\n106  106     0    173.30 -0.331795\n107  107     0    174.21 -0.212375\n108  108     0    173.27 -0.335732\n109  109     0    173.70 -0.279303\n110  110     0    173.44 -0.313423\n111  111     0    173.75 -0.272742\n112  112     0    173.30 -0.331795\n113  113     0    200.00  3.172069\nDer Wert 200 cm in Zeile 113 scheint fehlerhaft zu sein. Eine Eigendehnung der Feder um zusätzliche 16 Zentimeter ist nicht plausibel. Auch der z-Wert &gt; 3 kennzeichnet den Messwert als Ausreißer. Die Zeile wird deshalb aus dem Datensatz entfernt.\nhier Aufklapper Normalverteilung\nhooke.drop(index = 113, inplace = True)\n\nhooke.groupby(by = 'mass')['distance'].describe()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nmass\n\n\n\n\n\n\n\n\n\n\n\n\n0\n11.0\n173.630909\n0.367409\n173.27\n173.3100\n173.440\n173.9300\n174.21\n\n\n100\n11.0\n171.044545\n0.985833\n170.15\n170.3650\n170.800\n171.2400\n173.56\n\n\n201\n11.0\n167.791818\n0.296305\n167.26\n167.7200\n167.780\n167.9750\n168.19\n\n\n301\n10.0\n163.710000\n1.660977\n161.60\n162.0575\n163.825\n165.3250\n165.86\n\n\n401\n10.0\n161.967000\n0.313229\n161.42\n161.8450\n161.915\n162.0250\n162.48\n\n\n452\n10.0\n160.713000\n0.627854\n159.98\n160.4575\n160.555\n160.7400\n161.83\n\n\n503\n10.0\n159.314000\n0.781099\n158.43\n158.6400\n159.220\n159.9650\n160.61\n\n\n554\n10.0\n157.547000\n0.523791\n156.92\n157.2075\n157.435\n157.7100\n158.60\n\n\n605\n10.0\n156.142000\n0.354206\n155.62\n156.0700\n156.080\n156.2075\n156.84\n\n\n655\n11.0\n154.022727\n0.224414\n153.72\n153.8800\n153.920\n154.2400\n154.35\n\n\n705\n9.0\n153.008889\n0.241425\n152.74\n152.8100\n152.910\n153.2700\n153.29\nHiernach ist die höchste Standardabweichung für die Messreihe mit 301 Gramm zu verzeichnen. Die gemessenen Werte sind jedoch unauffällig.\ngewicht = 301\n\nz_values = hooke[hooke['mass'] == gewicht].loc[: , 'distance'].apply(lambda x: (x - hooke[hooke['mass'] == gewicht].loc[: , 'distance'].mean()) /  hooke[hooke['mass'] == gewicht].loc[: , 'distance'].std())\nz_values.name = 'z-values'\n\nprint(pd.concat([hooke[hooke['mass'] == gewicht], z_values], axis = 1))\n\n    no  mass  distance  z-values\n70  70   301    162.38 -0.800734\n71  71   301    161.93 -1.071658\n72  72   301    161.95 -1.059617\n73  73   301    161.60 -1.270337\n74  74   301    164.59  0.529809\n75  75   301    165.86  1.294419\n76  76   301    163.82  0.066226\n77  77   301    163.83  0.072247\n78  78   301    165.57  1.119823\n79  79   301    165.57  1.119823\nDie Grafik des bereinigten Datensatzes legt einen linearen Zusammenhang nahe. Darüber hinaus sticht der mit zunehmendem Gewicht abfallende Trend der Datenpunkte ins Auge.\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = 'bereinigter Datensatz', ylabel = 'Abstand in cm', xlabel = 'Gewicht in Gramm')\nEntsprechend des Versuchsaufbaus nimmt mit zunehmender Dehnung der Feder der Abstand zum Abstandssensor ab. Da die Federausdehnung gemessen werden soll, bietet es sich an, die Daten entsprechend zu transformieren. Dazu wird der gemessene Abstand bei 0 Gramm Gewicht als Nullpunkt aufgefasst, von dem aus die Federdehnung gemessen wird. Das bedeutet, dass von allen Datenpunkten das arithmetische Mittel der für 0 Gramm Gewicht gemessen Ausdehnung abgezogen und das Ergebnis mit -1 multipliziert wird.\nnullpunkt = hooke[hooke['mass'] == 0].loc[: , 'distance'].mean()\nprint(f\"Nullpunkt: {nullpunkt:.2f} cm\")\n\nhooke['distance'] = hooke['distance'].sub(nullpunkt).mul(-1)\n\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = 'bereinigter und invertierter Datensatz', ylabel = 'Federausdehnung in cm', xlabel = 'Gewicht in Gramm')\n\nNullpunkt: 173.63 cm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Messreihe Hooke'sches Gesetz</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html#federkonstante-bestimmen",
    "href": "skript/hooke.html#federkonstante-bestimmen",
    "title": "2  Messreihe Hooke’sches Gesetz",
    "section": "2.1 Federkonstante bestimmen",
    "text": "2.1 Federkonstante bestimmen\nDie Beziehung zwischen der Kraft \\(F\\) und der Längenänderung \\(\\Delta{x}\\) einer Feder mit Federkonstante \\(k\\) wird durch die Gleichung \\(F = k \\times \\Delta{x}\\) beschrieben. Dabei entspricht die Kraft \\(F\\) dem mit der Fallbeschleunigung \\(g\\) multiplizierten Gewicht in Kilogramm \\(m\\). Die Fallbeschleunigung beträgt auf der Erde \\(9,81 \\frac{m}{s^2}\\).\nDeshalb wird im Datensatz das in der Spalte ‘mass’ eingetragene Gewicht in Gramm in die wirkende Kraft umgerechnet. Ebenso wird die gemessene Abstandsänderung in der Spalte ‘distance’ von Zentimeter in Meter umgerechnet.\n\nhooke['mass'] = hooke['mass'].div(1000).mul(9.81)\nhooke.rename(columns = {'mass': 'force'}, inplace = True)\n\nhooke['distance'] = hooke['distance'].div(100)\n\nprint(hooke.head())\n\n   no    force  distance\n0   0  6.91605  0.203409\n1   1  6.91605  0.208909\n2   2  6.91605  0.203609\n3   3  6.91605  0.208209\n4   4  6.91605  0.208609\n\n\nFür die grafische Darstellung des Zusammenhangs \\(F = k \\times \\Delta{x}\\) ist es zweckmäßiger, die Abstandsänderung auf der x-Achse und die wirkende Kraft auf der y-Achse darzustellen.\n\nhooke.plot(x = 'distance', y = 'force', kind = 'scatter', title = 'umgeformter Datensatz', ylabel = 'wirkende Kraft in $N$', xlabel = 'Abstandsänderung in Meter')\n\n\n\n\n\n\n\n\n\nLineare Ausgleichsrechnung\nDie Ausgleichsrechnung (oder auch Parameterschätzung) ist eine Methode, um für eine Messreihe die unbekannten Parameter des zugrundeliegenden physikalischen Modells zu schätzen. Das Ziel besteht darin, eine (in diesem Fall lineare) Funktion zu bestimmen, die bestmöglich an die Messdaten angepasst ist. (Wikipedia)\nEine lineare Funktion wird durch die Konstante \\(\\beta_0\\), den Schnittpunkt mit der y-Achse, und den Steigungskoeffizienten \\(\\beta_1\\) bestimmt.\n\\[\ny = \\beta_0 + \\beta_1 \\times x\n\\]\nZur Bestimmung der Parameter einer linearen Funktion wird die Methode der linearen Regression verwendet. Die Funktionen dafür stellt das Paket numpy.polynomial bzw. für Polynomfunktionen dessen Modul numpy.polynomial.polynomial bereit.\n\nimport numpy.polynomial.polynomial as poly\n\n\npolyfit und polyeval\nZur Schätzung von Funktionsparametern nach der Methode der kleinsten Quadrate wird die Funktion poly.polyfit(x, y, deg) verwendet. x sind die Werte der unabhängigen Variablen, y die Werte der abhängigen Variablen und deg spezifiziert den Grad der gesuchten Polynomfunktion. deg = 1 spezifiziert eine lineare Funktion.\n\n\n\n\n\n\nBeispiel 2.2: polyfit und polyeval erklärt\n\n\n\n\n\n\n# Beispieldaten erzeugen\nx = np.array(list(range(0, 100)))\ny = x ** 2\n\nprint(np.polynomial.polynomial.polyfit(x, y, 1))\n\n[-1617.    99.]\n\n\nDie Funktion gibt die geschätzten Regressionsparameter als NumPy-Array zurück. Die Terme sind aufsteigend angeordnet, d. h. der Achsabschnitt steht an Indexposition 0, der Steigungskoeffizient an Indexposition 1. Die Ausgabe für ein Polynom zweiten Grades würde beispielsweise so aussehen:\n\nprint(np.polynomial.polynomial.polyfit(x, y, 2))\n\n[3.15891594e-13 1.90464004e-14 1.00000000e+00]\n\n\nMit den Regressionskoeffizienten können die Vorhersagewerte der linearen Funktion berechnet werden. Dafür kann die Funktion poly.polyeval(x, c) verwendet werden. Diese berechnet die Funktionswerte für in x übergebene Wert(e) mit den Funktionsparametern c.\n\n# 'manuelle' Berechnung\nregressions_koeffizienten = np.polynomial.polynomial.polyfit(x, y, 1)\nvorhersagewerte = regressions_koeffizienten[0] + x * regressions_koeffizienten[1]\n\n# Berechnung mit polyeval\nlm = np.polynomial.polynomial.polyfit(x, y, 1)\nvorhersagewerte_polyval = np.polynomial.polynomial.polyval(x, lm)\n\nprint(\"Die Ergebnisse stimmen überein:\", np.equal(vorhersagewerte, vorhersagewerte_polyval).all())\nprint(\"\\nAusschnitt der Vorhersagewerte:\", vorhersagewerte[:10])\n\nDie Ergebnisse stimmen überein: True\n\nAusschnitt der Vorhersagewerte: [-1617. -1518. -1419. -1320. -1221. -1122. -1023.  -924.  -825.  -726.]\n\n\nDas Bestimmtheitsmaß \\(R^2\\) gibt an, wie gut die Schätzfunktion an die Daten angepasst ist. Der Wertebereich reicht von 0 bis 1. Ein Wert von 1 bedeutet eine vollständige Anpassung. Für eine einfache lineare Regression mit nur einer erklärenden Variable kann das Bestimmtheitsmaß als Quadrat des Bravais-Pearson-Korrelationskoeffizienten \\(r\\) berechnet werden. Dieser wird mit der Funktion np.corrcoef(x, y) ermittelt (die eine Matrix der Korrelationskoeffizienten ausgibt).\n\nprint(f\"r = {np.corrcoef(x, y)[0, 1]:.2f}\")\nprint(f\"R\\u00b2 = {np.corrcoef(x, y)[0, 1] ** 2:.2f}\")\n\nr = 0.97\nR² = 0.94\n\n\nDie Daten und die geschätzte Gerade können grafisch dargestellt werden.\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(x, y, label = 'Beispieldaten')\nplt.plot(x, vorhersagewerte, label = 'Vorhersagewerte')\nplt.annotate(\"$R^2$ = {:.2f}\".format(np.corrcoef(x, y)[0, 1] ** 2), (max(x) * 0.9, 1))\n\nplt.title(label = 'Beispieldaten und geschätzte Linearfunktion')\nplt.xlabel('x-Werte')\nplt.ylabel('y-Werte')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeispiel 2.3: to do: numpy.polyfit & numpy.polyval\n\n\n\n\n\nin den Aufklapper verschieben legacy - wichtigster Unterschied: Ausgabe der Koeffizienten in umgekehrter Reihenfolge!\nWarnung / ein Hinweis, dass man es nicht mehr benutzen soll. https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\nHier auch noch mal deutlicher: https://numpy.org/doc/stable/reference/routines.polynomials.html “As noted above, the poly1d class and associated functions defined in numpy.lib.polynomial, such as numpy.polyfit and numpy.poly, are considered legacy and should not be used in new code. Since NumPy version 1.4, the numpy.polynomial package is preferred for working with polynomials.”\npolyfit https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\npolyval numpy.polyval(p, x) … evaluiere Wert(e) p mit Modellkoeffizienten x.\nhttps://numpy.org/doc/stable/reference/generated/numpy.polyval.html\n\n\n\nFederkonstante bestimmen\nDie Parameter der an die Messwerte angepassten linearen Funktion und das Bestimmtheitsmaß lauten:\n\nprint(np.polynomial.polynomial.polyfit(hooke['distance'], hooke['force'], 1))\n\nprint(f\"r = {np.corrcoef(hooke['distance'], hooke['force'])[0, 1]:.2f}\")\nprint(f\"R\\u00b2 = {np.corrcoef(hooke['distance'], hooke['force'])[0, 1] ** 2:.2f}\")\n\n[ 0.05753159 33.01899551]\nr = 0.99\nR² = 0.99\n\n\nMit den Regressionskoeffizienten können die Vorhersagewerte der linearen Funktion berechnet werden.\n\n# Berechnung mit polyeval\nlm = np.polynomial.polynomial.polyfit(hooke['distance'], hooke['force'], 1)\nvorhersagewerte_hooke = np.polynomial.polynomial.polyval(hooke['distance'], lm)\n\nDie Messreihe und die darauf angepasste lineare Funktion können grafisch dargestellt werden.\n\n# Platzhalter\nx = hooke['distance']\ny = hooke['force']\n\n# Plot erstellen\nplt.scatter(x, y, label = 'Messdaten')\nplt.plot(x, vorhersagewerte_hooke, label = 'Vorhersagewerte')\nplt.annotate(\"$R^2$ = {:.2f}\".format(np.corrcoef(x, y)[0, 1] ** 2), (max(x) * 0.9, 1))\n\nplt.title(label = 'Messdaten und geschätzte Linearfunktion')\nplt.xlabel('gemessene Abstandsänderung')\nplt.ylabel('wirkende Kraft')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMessabweichung quantifizieren\nKonfidenzintervall des Regressionskoeffizienten berechnen:\nhttps://mountain-hydrology-research-group.github.io/data-analysis/modules/module4/lab4-3.html\n(benötigt aber stats für die t-Verteilung)\nto do: plt.errorbar (capsize = 3 macht kleine Linien an den Enden der Kerze)\nwann / wozu braucht man das: Durch Umstellen nach der Federkonstante \\(k\\) kann diese wie folgt ermittelt werden:\n\\[\nk = \\frac{m \\times g}{\\Delta{x}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Messreihe Hooke'sches Gesetz</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#das-modul-scipy",
    "href": "skript/einleitung.html#das-modul-scipy",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.2 Das Modul SciPy",
    "text": "1.2 Das Modul SciPy\nDie Berechnung der Normalverteilungsfunktion mit Python wie in Beispiel 1.4 ist nicht sonderlich handlich. Funktionen zur Berechnung von Dichtekurven können über das Modul stats aus dem Paket SciPy importiert werden.\nFunktionen für die Normalverteilung werden wie folgt aufgerufen. Das Modul umfasst zahlreiche Verteilungen, bspw. auch die t-Verteilung.\n\nimport scipy\nprint(\"Häufigkeitdichte der Normalverteilung:\", scipy.stats.norm.pdf(0), \"\\n\")\n\n# t Verteilungen\nprint(\"Häufigkeitdichte der t-verteilung:\", scipy.stats.t.pdf(0, df = 1))\n\nHäufigkeitdichte der Normalverteilung: 0.3989422804014327 \n\nHäufigkeitdichte der t-verteilung: 0.31830988618379075\n\n\n\ndie x-Werte sind = np.linspace(min(bin_edges), max(bin_edges), 100).\n\nalternativ kann man auch np.linspace(stichprobenmittelwert -4 * stichprobenstandardabweichung, stichprobenmittelwert +4 * stichprobenstandardabweichung, 100) benutzen.\n\ndie y-Werte sind die Dichtefunktion der x-Werte\n\nscipy.stats.norm.pdf(x-Werte)\n\n\nAber das muss man nicht alles ausrechnen: Paket SciPy, Modul stats (Statistical functions)\nscipy.stats.norm.\n\n\n\n\n\n\n\n\nscipy.stats.norm.\nBeschreibung\nBeispiel\n\n\n\n\npdf(x)\nProbability density function (PDF) = Dichte der Normalverteilung am Punkt x \\(f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} ~ e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\)\nscipy.stats.norm.pdf(x = 0) np.float64(0.3989422804014327) ca. 0.4 * Klassenbreite aller Werte liegen in dieser Klasse\n\n\ncdf(x)\nCumulative density function (CDF) = Anteil der Werte links von x\nscipy.stats.norm.cdf(x = 0) np.float64(0.5) 0.5 aller Werte liegen links von 0 scipy.stats.norm.cdf(1) - scipy.stats.norm.cdf(-1) np.float64(0.6826894921370859) 0.68 aller Werte liegen im Intervall von -1 und 1\n\n\nppf(q)\nPercentile point function (CDF inverse) = Wert in Einheiten der Standardabweichung, links von dem der Anteil q aller Werte liegt Formel (?)\nscipy.stats.norm.ppf(q = 0.025) np.float64(-1.9599639845400545) scipy.stats.norm.ppf(q = 0.975) np.float64(1.959963984540054) z-Werte für das zweiseitige 95 % Konfidenzintervall\n\n\nrvs(size = 1)\nsize Zufallszahlen aus der Normalverteilung mit den Parametern loc = 0 (Mittelwert) und scale = 1 (Standardabweichung).\nscipy.stats.norm.rvs(size = 5) array([ 0.75535185, 0.61859334, -0.46476293, 0.10680733, -0.58640349])\n\n\n\n\nplt.hist(dose2, bins = 7, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\n# Normalverteilung berechnen.\nhist, bin_edges = np.histogram(dose2, bins = 7)\n\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\n\n## Normalverteilungsfunktion mit Python berechnen\ny_values =  1 / (dose2_std * np.sqrt(2 * np.pi)) * np.exp(- (x_values - dose2_mean) ** 2 / (2 * dose2_std ** 2))\nplt.plot(x_values, y_values, label = 'Normalverteilung', lw = 4)\n\n## scipy\ny_values_scipy = scipy.stats.norm.pdf(x_values, loc = dose2_mean, scale = dose2_std )\nplt.plot(x_values, y_values_scipy, label = 'scipy', linestyle = 'dashed')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDie Annäherung der Verteilung von Messwerten an die Normalverteilung wird anhand des Gewichts von Pinguinen aus dem Datensatz palmerpenguins gezeigt.\n\npalmerpenguins\n\n\n\nPinguine des Palmer-Station-Datensatzes\n\n\nMeet the Palmer penguins von @allison_horst steht unter der Lizenz CC0-1.0 und ist auf GitHub abrufbar. 2020\nDer Datensatz steht unter der Lizenz CCO und ist in R sowie auf GitHub verfügbar. 2020\n# R Befehle, um den Datensatz zu laden\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\nHorst AM, Hill AP und Gorman KB. 2020. palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.\n\npenguins = pd.read_csv(filepath_or_buffer = \"c:/Users/mapoe004/Desktop/Arbeitsordner Maik Poetzsch/BCD/Bausteine/Werkzeugbausteine/w-Pandas/w-pandas/skript/01-daten/penguins.csv\")\n\n# Tiere mit unvollständigen Einträgen entfernen\npenguins.drop(np.where(penguins.apply(pd.isna).any(axis = 1))[0], inplace = True)\n\nprint(penguins.info(), \"\\n\");\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 333 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 23.4+ KB\nNone \n\n\n\n\n \nDer Datensatz enthält Daten für drei Pinguinarten.\n\nprint(penguins.groupby(by = penguins['species']).size())\n\nspecies\nAdelie       146\nChinstrap     68\nGentoo       119\ndtype: int64\n\n\nUnter anderen wurde das Körpergewicht in Gramm gemessen, das in der Spalte ‘body_mass_g’ eingetragen ist.\n\nGrafikCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (7.5, 6), sharey = True, layout = 'tight')\nplt.suptitle('Gewichtsverteilung von Pinguinen')\n\n# Adelie\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[0]]\n\n## Histogramm\nax1.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C0', density = True)\nax1.set_xlabel('Gewicht in Gramm')\nax1.set_ylabel('Häufigkeitsdichte')\nax1.set_title(label = penguins['species'].unique()[0] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[0]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax1.plot(x_values, y_values, color = 'black', linewidth = 1, label = 'Normalverteilung')\nax1.set_label('Normalverteilungskurve')\nax1.legend()\n\n# Chinstrap\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[1]]\n\n## Histogramm\nax2.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C1', density = True)\nax2.set_xlabel('Gewicht in Gramm')\nax2.set_title(label = penguins['species'].unique()[1] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[1]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax2.plot(x_values, y_values, color = 'black', linewidth = 1)\n\n# Gentoo\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[2]]\n\n## Histogramm\nax3.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C2', density = True)\nax3.set_xlabel('Gewicht in Gramm')\nax3.set_title(label = penguins['species'].unique()[2] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[2]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax3.plot(x_values, y_values, color = 'black', linewidth = 1)\n\nplt.show()\n\n\n\n\n\nAufgabe Normalverteilung\nAufgabe: Histogramm von (meerschweinchen[‘len’] mit 7 bins und mit Normalverteilungskurve zeichnen\n\n\n\n\n\n\n\n\n\nIm nächsten Schritt wollen wir auf den tatsächlichen Mittelwert der Pinguine schließen\nDie Überlegung, dass von Stichprobenwerten auf den tatsächlichen Wert in der Grundgesamtheit geschlossen werden kann, ist (beispielsweise für den Mittelwert) wie folgt:\n\nWenn eine Stichprobe aus einer Grundgesamtheit gezogen wird, dann streuen die Stichprobenwerte normalverteilt um den Mittelwert der Grundgesamtheit. Bei einer Normalverteilung liegen\n\n68,27 % aller Werte im Intervall \\(\\pm 1 ~ s\\),\n95,45 % aller Werte im Intervall \\(\\pm 2 ~ s\\) und\n99,73 % aller Werte im Intervall \\(\\pm 3 ~ s\\).\n\nMit der gleichen Wahrscheinlichkeitsverteilung liegt der unbekannte Mittelwert der Grundgesamtheit um einen zufälligen Wert aus der Stichprobe.\nDer Erwartungswert kann mit einer gewissen Wahrscheinlichkeit aus dem Standardfehler des Mittelwerts einer Stichprobe geschätzt werden.\n\nder Erwartungswert liegt in 68,27 % aller Fälle im Intervall \\(\\pm 1 ~ \\frac{s}{\\sqrt{n}}\\),\nder Erwartungswert liegt in 95,45 % aller Fälle im Intervall \\(\\pm 2 ~ \\frac{s}{\\sqrt{n}}\\) und\nder Erwartungswert liegt in 99,73 % aller Fälle im Intervall \\(\\pm 3 ~ \\frac{s}{\\sqrt{n}}\\).\n\n\nHäufig wird das Konfidenzintervall 95 % gewählt, was \\(\\pm 1.96 ~ \\frac{s}{\\sqrt{n}}\\) entspricht.\n(für n &lt; 30 folgen die Stichprobenmittelwerte einer t-Verteilung, die sich für n &gt; 30 der Normalverteilung annähert.)\nstatt: scipy.stats.norm.cdf(1) nimmt man: scipy.stats.t.cdf(1, df = 4), wobei df Stichprobengröße -1 ist.\nFür eine Stichprobengröße von 4 gilt: scipy.stats.t.cdf(1, df = 4) - scipy.stats.t.cdf(- 1, df = 4) np.float64(0.626099033699941) –&gt; 62,6 % der Werte\nscipy.stats.t.cdf(2, df = 4) - scipy.stats.t.cdf(- 2, df = 4) np.float64(0.8838834764831844)\nscipy.stats.t.cdf(2, df = 4) - scipy.stats.t.cdf(- 2, df = 4) np.float64(0.8838834764831844)\nSchritte zur Berechnung:\nBestimme den Stichprobenmittelwert (\\bar{x}).\nBestimme (s) (Stichprobenstandardabweichung) oder (\\sigma).\nBestimme (n) (Stichprobengröße).\nWähle das Konfidenzniveau und bestimme den entsprechenden Z- oder t-Wert.\nBerechne das Konfidenzintervall mit den obigen Formeln.\nEin höheres Konfidenzniveau ergibt ein breiteres Intervall, dass mit höherer Sicherheit den wahren Mittelwert abdeckt.\n–&gt; Normalverteilung und die Wahrscheinlichkeiten erklären - 1standardfehler, 2standardfehler, 3standardfehler = Konfidenzintervalle –&gt; das wird zu kompliziert oder?\nto do: fig-alt\nto do: panel Stichprobe mit Streuung in Intervallen des Standardfehlers\n\nStandardnormalverteilungEinzelner MesswertStichprobe N = 12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptisch ist das nicht schön… das sollte an der geringen Standardabweichung von ~ 0.2 in der Stichprobe liegen. Das staucht die Kurve. To do: Kontrollieren, ob alles richtig ist.\n\n\n\n\n\n\n\n\n\n\n\n\nAufgabe könnte das plotten der Schnabellänge sein\n\n\n\n\nSchnabeldimensionen\n\n\nBill dimensions von @allison_horst steht unter der Lizenz CC0-1.0 und ist auf GitHub abrufbar. 2020\n\n \nEinen Überblick über den Datensatz verschafft die Methode DataFrame.info().\n\nprint(penguins.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 333 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 23.4+ KB\nNone\n\n\nGilt auch für Messungen: Wenn sehr häufig gemessen wird\nDas plotten ist aber aufwändig, weil man alles manuell erstellen muss. –&gt; optional / für später\n\nWenn eine Stichprobe aus einer Grundgesamtheit gezogen wird, dann streut der Stichprobenmittelwert um den Mittelwert der Grundgesamtheit, also den Erwartungswert. Anhand des Würfelexperiments wurde gezeigt, dass mit zunehmender Stichprobengröße Stichprobenmittelwerte in der Nähe des Erwartungswerts immer wahrscheinlicher werden als solche, die weiter entfernt liegen.\n\n\nDie ideale Messung\n\n\n\n\n\n\nDefinition 1.3: ideale Messung\n\n\n\n\nDie ideale Messung ist eine direkte Messung oder der gesuchte Wert hängt linear (direkt?!) vom gemessenen Wert ab.\nDie ideale Messung ist genau und präzise.\n\n\n\n\n\nDirekte und indirekte Messung\nBei einer direkten Messung wird die Messgröße durch den unmittelbaren Vergleich mit einem Normal oder einem genormten Bezugssystem gewonnen.\n\n\n\n\n\n\n\n\n\nBalkenwaage\n\n\n\n\n\n\n\nZollstock\n\n\n\n\n\n\nAbbildung 1.2: Direkte Messung\n\n\n\nGliedermaßstäbe von Fst76 ist lizensiert unter CC-BY-SA 3.0 und ist abrufbar auf Wikimedia. 2014\n\n \nBei einer indirekten Messung wird die Messgröße auf eine andere pyhsikalische Größe zurückgeführt.\n\n\n\n\n\n\n\n\n\nFederwaage\n\n\n\n\n\n\n\nLaserentfernungsmessung\n\n\n\n\n\n\nAbbildung 1.3: Indirekte Messung\n\n\n\nSpring scale von Amada44 steht unter der Lizenz CC-BY-SA-3.0 unported und ist abrufbar auf Wikimedia. 2016\nObserve the Moon wurde von der NASA veröffentlicht und ist abrufbar unter nasa.gov. 2010\n\n\n\nGenauigkeit und Präzision\n(gehört zu linearer Regression muss es aber nicht sein)\nDie Genauigkeit\nVerzerrung (Bias): https://de.wikipedia.org/wiki/Verzerrung_einer_Sch%C3%A4tzfunktion quantifiziert das systematische Über- oder Unterschätzen der Schätzfunktion",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#messung",
    "href": "skript/einleitung.html#messung",
    "title": "1  Das Prinzip von Messungen",
    "section": "",
    "text": "Definition 1.1: Messung\n\n\n\n“Eine Messung ist der experimentelle Vorgang, durch den ein spezieller Wert einer physikalischen Größe als Vielfaches einer Einheit oder eines Bezugswertes ermittelt wird.\nDie Messung ergibt zunächst einen Messwert. Dieser stimmt aber aufgrund störender Einflüsse mit dem wahren Wert der Messgröße praktisch nie überein, sondern weist eine gewisse Messabweichung auf. Zum vollständigen Messergebnis wird der Messwert, wenn er mit quantitativen Aussagen über die zu erwartende Größe der Messabweichung ergänzt wird. Dies wird in der Messtechnik als Teil der Messaufgabe und damit der Messung verstanden.”\nMessung. von verschiedenen Autor:innen steht unter der Lizenz CC BY-SA 4.0 ist abrufbar auf Wikipedia https://de.wikipedia.org/wiki/Messung. 2025\n\nDie ideale Messung ist eine direkte Messung oder der gesuchte Wert hängt linear (direkt?!) vom gemessenen Wert ab.\nDie ideale Messung ist genau und präzise.\n\n\n\n\nDirekte und indirekte Messung\nBei einer direkten Messung wird die Messgröße durch den unmittelbaren Vergleich mit einem Normal oder einem genormten Bezugssystem gewonnen.\n\n\n\n\n\n\n\n\n\nBalkenwaage\n\n\n\n\n\n\n\nZollstock\n\n\n\n\n\n\nAbbildung 1.2: Direkte Messung\n\n\n\nGliedermaßstäbe von Fst76 ist lizensiert unter CC-BY-SA 3.0 und ist abrufbar auf Wikimedia. 2014\n\n \nBei einer indirekten Messung wird die Messgröße auf eine andere pyhsikalische Größe zurückgeführt.\n\n\n\n\n\n\n\n\n\nFederwaage\n\n\n\n\n\n\n\nLaserentfernungsmessung\n\n\n\n\n\n\nAbbildung 1.3: Indirekte Messung\n\n\n\nSpring scale von Amada44 steht unter der Lizenz CC-BY-SA-3.0 unported und ist abrufbar auf Wikimedia. 2016\nObserve the Moon wurde von der NASA veröffentlicht und ist abrufbar unter nasa.gov. 2010\n\n \n\n\nGenauigkeit und Präzision\n\n\n\n\n\n\n\n\nGenauigkeit\n\n\n\n\n\n\n\nPräsizion\n\n\n\n\n\n\nDie Genauigkeit einer Messung ist ein Maß für die Abweichung der Messwerte vom realen Wert. Die Genauigkeit ist nur bestimmbar, wenn anerkannte Referenzwerte vorhanden sind.\n\n\nDie Präzision einer Messung beschreibt, wie gut die einzelnen Messwerte miteinander übereinstimmen. Die Präszision einer Messung wird über die Standardabweichung der Stichprobe bestimmt.\n\n\n\n\nAbbildung 1.4: Genauigkeit und Präzision",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#die-normalverteilung",
    "href": "skript/einleitung.html#die-normalverteilung",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.3 Die Normalverteilung",
    "text": "1.3 Die Normalverteilung\nMit zunehmender Stichprobengröße wird eine immer bessere Schätzung des Erwartungswerts erreicht. Mathematisch liegt dieser Beobachtung der zentrale Grenzwertsatz zugrunde. So werden beim Würfeln mit mehreren Würfeln weit vom Erwartungswert entfernte Wurfergebnisse immer unwahrscheinlicher. Dies lässt sich bereits mit wenigen Würfeln zeigen (siehe Beispiel).\n\n\n\n\n\n\nBeispiel 1.2: Häufigkeitsverteilung von Würfelergebnissen\n\n\n\n\n\nFür einen Würfel gibt es 6 mögliche Ergebnisse, für 2 Würfel 6 * 6 mögliche Kombinationen, für 3 Würfel 6 * 6 * 6 Kombinationen und so weiter. Weil viele Kombinationen wertgleich sind, kommen Wurfergebnisse in der Nähe des Erwartungswerts häufiger vor als beispielsweise ein Einserpasch.\n\nein Würfelzwei Würfeldrei Würfel\n\n\n\nein_würfel = []\n\nfor i in range(1, 7):\n  ein_würfel.append(i)\n\nein_würfel = pd.Series(ein_würfel)\n\nprint(\"Häufigkeitsverteilung der Augensumme:\")\nprint(ein_würfel.value_counts(), \"\\n\")\nprint(f\"Durchschnitt: {ein_würfel.mean():.1f}\")\n\nplt.bar(ein_würfel.unique(), ein_würfel.value_counts())\nplt.xlabel('Augenzahl')\nplt.ylabel('Anzahl Kombinationen')\nplt.show()\n\nHäufigkeitsverteilung der Augensumme:\n1    1\n2    1\n3    1\n4    1\n5    1\n6    1\nName: count, dtype: int64 \n\nDurchschnitt: 3.5\n\n\n\n\n\n\n\n\n\n\n\n\nzwei_würfel = []\n\nfor i in range(1, 7):\n  würfel_1 = i\n\n  for j in range (1, 7):\n    würfel_2 = j\n    zwei_würfel.append(würfel_1 + würfel_2)\n\nzwei_würfel = pd.Series(zwei_würfel)\n\nprint(\"Häufigkeitsverteilung der Augensumme:\")\nprint(zwei_würfel.value_counts().sort_index(ascending = True), \"\\n\")\nprint(f\"Durchschnitt: {zwei_würfel.mean():.1f}\")\nprint(f\"Durchschnitt pro Würfel: {zwei_würfel.mean() / 2:.1f}\")\n\nplt.bar(zwei_würfel.unique(), zwei_würfel.value_counts().sort_index(ascending = True))\nplt.xlabel('Augenzahl')\nplt.ylabel('Anzahl Kombinationen')\nplt.grid()\nplt.show()\n\nHäufigkeitsverteilung der Augensumme:\n2     1\n3     2\n4     3\n5     4\n6     5\n7     6\n8     5\n9     4\n10    3\n11    2\n12    1\nName: count, dtype: int64 \n\nDurchschnitt: 7.0\nDurchschnitt pro Würfel: 3.5\n\n\n\n\n\n\n\n\n\n\n\n\ndrei_würfel = []\n\nfor i in range(1, 7):\n  würfel_1 = i\n\n  for j in range (1, 7):\n    würfel_2 = j\n\n    for k in range (1, 7):\n      würfel_3 = k\n      drei_würfel.append(würfel_1 + würfel_2 + würfel_3)\n\ndrei_würfel = pd.Series(drei_würfel)\n\nprint(\"Häufigkeitsverteilung der Augensumme:\")\nprint(drei_würfel.value_counts().sort_index(ascending = True), \"\\n\")\nprint(f\"Durchschnitt: {drei_würfel.mean():.1f}\")\nprint(f\"Durchschnitt pro Würfel: {drei_würfel.mean() / 3:.1f}\")\n\nplt.bar(drei_würfel.unique(), drei_würfel.value_counts().sort_index(ascending = True))\nplt.xlabel('Augenzahl')\nplt.ylabel ('Anzahl Kombinationen')\nplt.grid()\nplt.show()\n\nHäufigkeitsverteilung der Augensumme:\n3      1\n4      3\n5      6\n6     10\n7     15\n8     21\n9     25\n10    27\n11    27\n12    25\n13    21\n14    15\n15    10\n16     6\n17     3\n18     1\nName: count, dtype: int64 \n\nDurchschnitt: 10.5\nDurchschnitt pro Würfel: 3.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie t-Verteilung müsste eingeführt werden.\nDie mit steigender Stichprobengröße zu beobachtende Annäherung von Messdaten an einen in der Grundgesamtheit geltenden Erwartungswert gilt auch, wenn der Erwartungswert und die Varianz in der Grundgesamtheit unbekannt sind. Mit zunehmender Stichprobengröße nähert sich die t-Verteilung der Messwerte der Normalverteilung an, die nach ihrem Entdecker Carl Friedrich Gauß auch als Gaußsche Glockenkurve bekannt ist.\nDie Normalverteilung ist eine Dichtekurve, an die sich der Verlauf eines Histogramms mit einer gegen unendlich gehenden Anzahl von Messwerten und einer gegen Null gehenden Klassenbreite annähert.\n\n\n\n\n\n\nDefinition 1.2: Histogramm\n\n\n\n\n\nDas Histogramm ist eine grafische Darstellung der Häufigkeitsverteilung kardinal skalierter Merkmale. Die Daten werden in Klassen, die eine konstante oder variable Breite haben können, eingeteilt. Es werden direkt nebeneinanderliegende Rechtecke von der Breite der jeweiligen Klasse gezeichnet, deren Flächeninhalte die (relativen oder absoluten) Klassenhäufigkeiten darstellen. Die Höhe jedes Rechtecks stellt dann die (relative oder absolute) Häufigkeitsdichte dar, also die (relative oder absolute) Häufigkeit dividiert durch die Breite der entsprechenden Klasse.\n\n\n\n\n\n\nBeispiel 1.3: Histogramm berechnen und visualisieren\n\n\n\n\n\nAls Beispiel wird die Länge der zahnbildenden Zellen der Meerschweinchen verwendet, die eine Vitamin-C-Dosis von 2 erhielten.\n\ndose2 = meerschweinchen.loc[meerschweinchen['dose'] == 2, 'len']\nprint(*list(dose2)) # * = Ausgabe ohne Kommata\nprint(\"N\", len(dose2), \"Minimum:\", dose2.min(), \"Maximum:\", dose2.max(), \"Spannweite\", dose2.max() - dose2.min())\n\n23.6 18.5 33.9 25.5 26.4 32.5 26.7 21.5 23.3 29.5 25.5 26.4 22.4 24.5 24.8 30.9 26.4 27.3 29.4 23.0\nN 20 Minimum: 18.5 Maximum: 33.9 Spannweite 15.399999999999999\n\n\nMit der Funktion np.histogram(a, bins = 10, range = None, density = None) kann ein Histogramm berechnet werden.\n\na sind die zu berechnenden Daten\nbins spezifiziert die Anzahl an Klassen, standardmäßig werden 10 gewählt.\nrange = (float, float) erlaubt es, die untere und obere Grenze der Klassen festzulegen.\ndensity = True erlaubt es statt der absoluten Häufigkeiten, den Wert der Häufigkeitsdichtefunktion darzustellen. Dies berechnet sich wie folgt:\n\nrelative Häufigkeit = Anzahl Werte je Klasse / Anzahl aller Werte\nHäufigkeitsdichte = Anzahl Werte je Klasse / (Anzahl aller Werte * Klassenbreite)\nKlassenbreite = Maximum(Werte) - Minimum(Werte) / Anzahl Klassen\n\n\nFür die überschaubare Anzahl an Werten wird ein Histogramm mit 5 Klassen berechnet. Zum Vergleich wird auch die Häufigkeitsdichte ausgegeben.\n\nprint(np.histogram(dose2, bins = 5))\nprint(\"Häufigkeitsdichte:\", np.histogram(dose2, bins = 5, density = True)[0])\n\n(array([2, 5, 8, 2, 3]), array([18.5 , 21.58, 24.66, 27.74, 30.82, 33.9 ]))\nHäufigkeitsdichte: [0.03246753 0.08116883 0.12987013 0.03246753 0.0487013 ]\n\n\nDie Funktion np.histogram() gibt an erster Stelle ein array mit den absoluten Häufigkeiten bzw. der Häufigkeitsdichte jeder Klasse zurück. An zweiter Stelle wird ein array mit den x-Positionen der Klassenrechtecke zurückgegeben - dabei wird für jede Klasse die Position der linken Seite sowie für die letzte Klasse zusätzlich die Position der rechten Seite des Rechtecks ausgegeben. Für 5 Klassen werden also 6 Positionswerte ausgegeben.\nDie Klassenbreite kann zum Beispiel mit der Methode np.diff() ausgegeben werden.\n\nhist_abs, bin_edges = np.histogram(dose2, bins = 5)\nklassenbreite = np.diff(bin_edges)\nprint(klassenbreite)\n\n[3.08 3.08 3.08 3.08 3.08]\n\n\nDurch Multiplikation der Häufigkeitsdichte mit der Klassenbreite können die relativen Häufigkeiten berechnet werden.\n\nhist_dichte = np.histogram(dose2, bins = 5, density = True)[0]\nhist_relativ = hist_dichte * klassenbreite\nprint(hist_relativ)\n\n[0.1  0.25 0.4  0.1  0.15]\n\n\nDie Summe der relativen Häufigkeiten ist 1.\nEin Histogramm kann mit der Funktion plt.hist(x, bins = None, *, range = None, density = False) aufgerufen werden, welche intern np.histogram() für die Berechnungen aufruft. Die Parameter der Funktion entsprechenen denen der NumPy-Funktion, wobei mit dem Argument x die darzustellenden Daten übergeben werden. Zusätzlich können verschiedene Grafikparameter übergeben werden.\nDie Funktion hat 3 Rückgabewerte: die absolute Häufigkeit der Klassen (bzw. wenn density = True die Häufigkeitsdichte), die x-Position der Rechtecke.\n\nabsolute Häufigkeitrelative HäufigkeitHäufigkeitsdichte\n\n\n\nplt.hist(dose2, bins = 5, edgecolor = 'black')\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('absolute Häufigkeit')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEine Darstellung der relativen Häufigkeiten ist nicht direkt möglich.\n\nhist_dichte, bins, ignore = plt.hist(dose2, bins = 5, density = True, edgecolor = 'black')\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# relative Häufigkeit berechnen\nklassenbreite = np.diff(bins)[0]\nhist_relativ = hist_dichte * klassenbreite\n\n# yticks erzeugen an der Position von min(hist_dichte) bis max(hist_dichte)\n# aber mit Werten von hist_relativ\nplt.yticks(ticks = np.linspace(min(hist_dichte), max(hist_dichte), len(hist_relativ)),\nlabels = np.linspace(hist_relativ.round(2).min(), hist_relativ.round(2).max(), len(hist_relativ)).round(3));\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('relative Häufigkeit')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nplt.hist(dose2, bins = 5, density = True, edgecolor = 'black')\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistogramme sind nicht immer gut geeignet, um die Verteilung einer Stichprobe zu charakterisieren. Der visuelle Eindruck hängt von der gewählten Klassenzahl ab - ein Beispiel:\n\n3 Klassen5 Klassen7 Klassen\n\n\n\nplt.hist(meerschweinchen['len'], bins = 3, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nplt.hist(meerschweinchen['len'], bins = 5, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nplt.hist(meerschweinchen['len'], bins = 7, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n \nMit einer Dichtekurve wird optisch der Übergang zu einem Histogramm mit einer gegen unendlich gehenden Anzahl von Klassen vollzogen. Dadurch gehen zwar Details verloren, aber es wird eine klare Darstellung erreicht.\nDie Dichtefunktion der Normalverteilung beschreibt, welcher Anteil der Werte innerhalb eines bestimmten Wertebereichs liegt. Bei der Berechnung der relativen Häufigkeiten in Beispiel 1.3 haben wir gesehen, dass die Summe der relativen Häufigkeiten 1 ist. Dies entspricht der Fläche unterhalb der Dichtekurve.\nDie Dichtefunktion der Normalverteilung ist definiert als:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} ~ e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n\\]\nDer Erwartungswert ist der höchste Punkt der Kurve. Die Wendepunkte der Kurve liegen jeweils eine Standardabweichung vom Mittelwert entfernt.\nEine Normalverteilung mit dem Mittelwert \\(\\mu = 0\\) und einer Standardabweichung \\(\\sigma = 1\\) heißt Standardnormalverteilung.\n\nNormalverteilung anpassen\nUm die Verteilung in einem Datensatz durch eine Normalverteilung anzunähern, werden dessen Mittelwert und Standardabweichung in die Funktionsgleichung der Normalverteilung eingesetzt. Mit Python können die Berechnungen direkt vorgenommen werden (siehe folgendes Beispiel). In der Handhabung einfacher sind die vom Paket SciPy bereitgestellten Funktionen, die im nächsten Abschnitt vorgestellt werden.\n\n\n\n\n\n\nBeispiel 1.4: Dichtekurven berechnen und darstellen\n\n\n\n\n\nBetrachten wir die Verteilungskennwerte der Gruppe der Meerschweinchen, die eine Dosis von 2 Milligramm Vitamin C erhielten.\n\nprint(verteilungskennwerte(dose2), \"\\n\");\n\ndose2_mean = verteilungskennwerte(dose2, output = False)[1]\ndose2_std = verteilungskennwerte(dose2, output = False)[4]\n\nprint(\"Exakter Mittelwert:\", dose2_mean)\nprint(\"Exakte Standardabweichung:\", dose2_std)\n\nN: 20\narithmetisches Mittel: 26.10\nStichprobenfehler: 0.84\nStichprobenvarianz: 14.24\nStandardabweichung: 3.77\nNone \n\nExakter Mittelwert: 26.1\nExakte Standardabweichung: 3.7741503052098744\n\n\nWenn wir die Standardabweichung und das arithmetische Mittel in die Normalverteilungsfunktion einsetzen, erhalten wir:\n\\[\nf(x) = \\frac{1}{3.7742 \\sqrt{2\\pi}} ~ e^{-\\frac{1}{2}\\left(\\frac{x-26.10}{3.7742}\\right)^2}\n\\]\n\\[\nf(x) = 0.1057 \\times e^{-\\frac{1}{2}\\left(\\frac{x-26.10}{3.7742}\\right)^2}\n\\]\nIn Python können die Berechnungen umgesetzt und grafisch dargestellt werden:\n\n# Histogram der Häufigkeitsdichte zeichnen\nplt.hist(dose2, bins = 7, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\n# Normalverteilung berechnen.\nhist, bin_edges = np.histogram(dose2, bins = 7)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\n\n## Dichtefunktion der Normalverteilung berechnen\ny_values =  1 / (dose2_std * np.sqrt(2 * np.pi)) * np.exp(- (x_values - dose2_mean) ** 2 / (2 * dose2_std ** 2))\n\n## Normalverteilungsfunktion mit Python berechnen\ny_values =  1 / (dose2_std * np.sqrt(2 * np.pi)) * np.exp(- (x_values - dose2_mean) ** 2 / (2 * dose2_std ** 2))\nplt.plot(x_values, y_values, label = 'Normalverteilung', lw = 4)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nQuelle: Skript MB S. 51-54\nDie Verteilung der Länge zahnbildender Zellen bei Meerschweinchen, die eine Dosis von 2 Milligramm Vitamin C erhielten, könnte einer Normalverteilung entsprechen. Aufgrund der geringen Stichprobengröße ist dies aber schwer zu beurteilen.\n\n\n \n\nDas Paket SciPy\nFunktionen zur Berechnung von Dichtekurven können über das Modul stats aus dem Paket SciPy importiert werden. Das Modul umfasst zahlreiche Verteilungen, bspw. auch die t-Verteilung. Funktionen für die Normalverteilung werden wie folgt aufgerufen:\n\nimport scipy\nprint(\"Häufigkeitsdichte der Normalverteilung bei x = 0:\", scipy.stats.norm.pdf(0), \"\\n\")\n\n# t Verteilungen\nprint(\"Häufigkeitsdichte der t-verteilung bei x = 0:\", scipy.stats.t.pdf(0, df = 1))\n\nHäufigkeitsdichte der Normalverteilung bei x = 0: 0.3989422804014327 \n\nHäufigkeitsdichte der t-verteilung bei x = 0: 0.31830988618379075\n\n\nFür die Normalverteilung sind vier Funktionen relevant:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.pdf(x) berechnet die Dichte der Normalverteilung am Punkt x (PDF = probability density function). x kann auch ein array sein - so wurde die linksstehende Kurve mit dem Befehl scipy.stats.norm.pdf(np.linspace(-4, 4, 100)) berechnet.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.cdf(x) berechnet den Anteil der Werte links von x (CDF = cumulative density function).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.ppf(q) ist die Quantilfunktion der Normalverteilung und die Umkehrfunktion der kumulativen Häufigkeitsdichtefunktion (CDF). Die Funktion berechnet für \\(0 \\le q \\le 1\\) den Wert x, links von dem der Anteil q aller Werte liegt und rechts von dem der Anteil 1-q liegt (PPF = percentile point function).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.rvs(size) zieht size Zufallszahlen aus der Normalverteilung.\n\n\n\nMit den Parametern loc = mittelwert und scale = standardabweichung kann die Form der Normalverteilung angepasst werden.\n\n\nAufgabe Normalverteilung\nhier ein paar Aufgaben, welche Anteile… usw. wenn scale = 15 und und mean = 100 ist (IQ-Verteilung)\n\nplt.hist(dose2, bins = 7, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\n# Normalverteilung berechnen.\nhist, bin_edges = np.histogram(dose2, bins = 7)\n\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\n\n## Normalverteilungsfunktion mit Python berechnen\ny_values =  1 / (dose2_std * np.sqrt(2 * np.pi)) * np.exp(- (x_values - dose2_mean) ** 2 / (2 * dose2_std ** 2))\nplt.plot(x_values, y_values, label = 'Normalverteilung', lw = 4)\n\n## scipy\ny_values_scipy = scipy.stats.norm.pdf(x_values, loc = dose2_mean, scale = dose2_std)\nplt.plot(x_values, y_values_scipy, label = 'scipy', linestyle = 'dashed')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDie Annäherung der Verteilung von Messwerten an die Normalverteilung wird anhand des Gewichts von Pinguinen aus dem Datensatz palmerpenguins gezeigt.\n\npalmerpenguins\n\n\n\nPinguine des Palmer-Station-Datensatzes\n\n\nMeet the Palmer penguins von @allison_horst steht unter der Lizenz CC0-1.0 und ist auf GitHub abrufbar. 2020\nDer Datensatz steht unter der Lizenz CCO und ist in R sowie auf GitHub verfügbar. 2020\n# R Befehle, um den Datensatz zu laden\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\nHorst AM, Hill AP und Gorman KB. 2020. palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.\n\npenguins = pd.read_csv(filepath_or_buffer = \"c:/Users/mapoe004/Desktop/Arbeitsordner Maik Poetzsch/BCD/Bausteine/Werkzeugbausteine/w-Pandas/w-pandas/skript/01-daten/penguins.csv\")\n\n# Tiere mit unvollständigen Einträgen entfernen\npenguins.drop(np.where(penguins.apply(pd.isna).any(axis = 1))[0], inplace = True)\n\nprint(penguins.info(), \"\\n\");\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 333 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 23.4+ KB\nNone \n\n\n\n\n \nDer Datensatz enthält Daten für drei Pinguinarten.\n\nprint(penguins.groupby(by = penguins['species']).size())\n\nspecies\nAdelie       146\nChinstrap     68\nGentoo       119\ndtype: int64\n\n\nUnter anderen wurde das Körpergewicht in Gramm gemessen, das in der Spalte ‘body_mass_g’ eingetragen ist.\n\nGrafikCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (7.5, 6), sharey = True, layout = 'tight')\nplt.suptitle('Gewichtsverteilung von Pinguinen')\n\n# Adelie\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[0]]\n\n## Histogramm\nax1.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C0', density = True)\nax1.set_xlabel('Gewicht in Gramm')\nax1.set_ylabel('Häufigkeitsdichte')\nax1.set_title(label = penguins['species'].unique()[0] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[0]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax1.plot(x_values, y_values, color = 'black', linewidth = 1, label = 'Normalverteilung')\nax1.set_label('Normalverteilungskurve')\nax1.legend()\n\n# Chinstrap\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[1]]\n\n## Histogramm\nax2.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C1', density = True)\nax2.set_xlabel('Gewicht in Gramm')\nax2.set_title(label = penguins['species'].unique()[1] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[1]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax2.plot(x_values, y_values, color = 'black', linewidth = 1)\n\n# Gentoo\ndata = penguins['body_mass_g'][penguins['species'] == penguins['species'].unique()[2]]\n\n## Histogramm\nax3.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C2', density = True)\nax3.set_xlabel('Gewicht in Gramm')\nax3.set_title(label = penguins['species'].unique()[2] + \" N = \" + str(penguins.groupby(by = penguins['species']).size().iloc[2]))\n\n## Normalverteilungskurve\nmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values =  1 / (stichprobenstandardabweichung * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mittelwert) ** 2 / (2 * stichprobenstandardabweichung ** 2))\n\nax3.plot(x_values, y_values, color = 'black', linewidth = 1)\n\nplt.show()\n\n\n\n\n\n\nAufgabe Normalverteilung\nAufgabe: Histogramm von (meerschweinchen[‘len’] mit 7 bins und mit Normalverteilungskurve zeichnen\n\n\n\n\n\n\n\n\n\nIm nächsten Schritt wollen wir auf den tatsächlichen Mittelwert der Pinguine schließen\nDie Überlegung, dass von Stichprobenwerten auf den tatsächlichen Wert in der Grundgesamtheit geschlossen werden kann, ist (beispielsweise für den Mittelwert) wie folgt:\n\nWenn eine Stichprobe aus einer Grundgesamtheit gezogen wird, dann streuen die Stichprobenwerte normalverteilt um den Mittelwert der Grundgesamtheit. Bei einer Normalverteilung liegen\n\n68,27 % aller Werte im Intervall \\(\\pm 1 ~ s\\),\n95,45 % aller Werte im Intervall \\(\\pm 2 ~ s\\) und\n99,73 % aller Werte im Intervall \\(\\pm 3 ~ s\\).\n\nMit der gleichen Wahrscheinlichkeitsverteilung liegt der unbekannte Mittelwert der Grundgesamtheit um einen zufälligen Wert aus der Stichprobe.\nDer Erwartungswert kann mit einer gewissen Wahrscheinlichkeit aus dem Standardfehler des Mittelwerts einer Stichprobe geschätzt werden. Um das Konfidenzintervall zu bestimmen, muss eine Vertrauenswahrscheinlichkeit gewählt werden.\n\nder Erwartungswert liegt in 68,27 % aller Fälle im Intervall \\(\\pm 1 ~ \\frac{s}{\\sqrt{n}}\\),\nder Erwartungswert liegt in 95,45 % aller Fälle im Intervall \\(\\pm 2 ~ \\frac{s}{\\sqrt{n}}\\) und\nder Erwartungswert liegt in 99,73 % aller Fälle im Intervall \\(\\pm 3 ~ \\frac{s}{\\sqrt{n}}\\).\n\n\nHäufig wird das Konfidenzintervall 95 % gewählt, was \\(\\pm 1.96 ~ \\frac{s}{\\sqrt{n}}\\) entspricht . (Das gilt aber nur für große Stichproben. Für kleine n folgen die Stichprobenmittelwerte einer t-Verteilung. Man sagt, dass sich die Werte der t-Verteilung ab n &gt; 30 der Normalverteilung annähern. Hier müsste man eigentlich die t-Verteilung vorstellen.)\nstatt: scipy.stats.norm.cdf(1) nimmt man: scipy.stats.t.cdf(1, df = 4), wobei df Stichprobengröße -1 ist.\nFür eine Stichprobengröße von 4 gilt: scipy.stats.t.cdf(1, df = 4) - scipy.stats.t.cdf(- 1, df = 4) np.float64(0.626099033699941) –&gt; 62,6 % der Werte\nscipy.stats.t.cdf(2, df = 4) - scipy.stats.t.cdf(- 2, df = 4) np.float64(0.8838834764831844)\nscipy.stats.t.cdf(2, df = 4) - scipy.stats.t.cdf(- 2, df = 4) np.float64(0.8838834764831844)\nSchritte zur Berechnung:\nBestimme den Stichprobenmittelwert (\\bar{x}).\nBestimme (s) (Stichprobenstandardabweichung) oder (\\sigma).\nBestimme (n) (Stichprobengröße).\nWähle das Konfidenzniveau und bestimme den entsprechenden Z- oder t-Wert.\nBerechne das Konfidenzintervall mit den obigen Formeln.\nEin höheres Konfidenzniveau ergibt ein breiteres Intervall, dass mit höherer Sicherheit den wahren Mittelwert abdeckt.\n–&gt; Normalverteilung und die Wahrscheinlichkeiten erklären - 1standardfehler, 2standardfehler, 3standardfehler = Konfidenzintervalle –&gt; das wird zu kompliziert oder?\nto do: fig-alt\nto do: panel Stichprobe mit Streuung in Intervallen des Standardfehlers\n\nStandardnormalverteilungEinzelner MesswertStichprobe N = 12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptisch ist das nicht schön… das sollte an der geringen Standardabweichung von ~ 0.2 in der Stichprobe liegen. Das staucht die Kurve. To do: Kontrollieren, ob alles richtig ist.\n\n\n\n\n\n\n\n\n\n\n\n\nAufgabe könnte das plotten der Schnabellänge sein\n\n\n\n\nSchnabeldimensionen\n\n\nBill dimensions von @allison_horst steht unter der Lizenz CC0-1.0 und ist auf GitHub abrufbar. 2020\n\n \nEinen Überblick über den Datensatz verschafft die Methode DataFrame.info().\n\nprint(penguins.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 333 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \n 7   year               333 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 23.4+ KB\nNone\n\n\nGilt auch für Messungen: Wenn sehr häufig gemessen wird\nDas plotten ist aber aufwändig, weil man alles manuell erstellen muss. –&gt; optional / für später\n\nWenn eine Stichprobe aus einer Grundgesamtheit gezogen wird, dann streut der Stichprobenmittelwert um den Mittelwert der Grundgesamtheit, also den Erwartungswert. Anhand des Würfelexperiments wurde gezeigt, dass mit zunehmender Stichprobengröße Stichprobenmittelwerte in der Nähe des Erwartungswerts immer wahrscheinlicher werden als solche, die weiter entfernt liegen.\nVerzerrung (Bias): https://de.wikipedia.org/wiki/Verzerrung_einer_Sch%C3%A4tzfunktion quantifiziert das systematische Über- oder Unterschätzen der Schätzfunktion",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  }
]