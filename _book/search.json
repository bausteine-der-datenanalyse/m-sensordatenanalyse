[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bausteine Computergestützter Datenanalyse",
    "section": "",
    "text": "Methodenbaustein Sensordatenanalyse\n\n\n\n\n\n\n\n\n\n\nBausteine Computergestützter Datenanalyse von Lukas Arnold, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch und Sebastian Seipel. Methodenbaustein Sensordatenanalyse von Maik Poetzsch ist lizensiert unter CC BY 4.0. Das Werk ist abrufbar auf GitHub. Ausgenommen von der Lizenz sind alle Logos Dritter und anders gekennzeichneten Inhalte. 2025\n\n\n\nZitiervorschlag\nArnold, Lukas, Simone Arnold, Florian Bagemihl, Matthias Baitsch, Marc Fehr, Maik Poetzsch, und Sebastian Seipel. 2025. „Bausteine Computergestützter Datenanalyse. Methodenbaustein Sensordatenanalyse. https://github.com/bausteine-der-datenanalyse/m-sensordatenanalyse.\nBibTeX-Vorlage\n@misc{BCD-m-sensordatenanalyse-2025,\n title={Bausteine Computergestützter Datenanalyse. Methodenbaustein Sensordatenanalyse},\n author={Arnold, Lukas and Arnold, Simone and Bagemihl, Florian and Baitsch, Matthias and Fehr, Marc and Poetzsch, Maik and Seipel, Sebastian},\n year={2025},\n url={https://github.com/bausteine-der-datenanalyse/m-sensordatenanalyse}} \n\n\n\nVoraussetzungen\nDie Bearbeitungszeit dieses Bausteins beträgt circa Platzhalter. Für die Bearbeitung dieses Bausteins werden folgende Bausteine vorausgesetzt und die genannten Bibliotheken verwendet:\n\nnumpy\n\nnumpy.polynomial\n\npandas\nmatplotlib\n\nQuerverweis auf:\n\n…\n\nIm Baustein werden folgende Daten verwendet:\n\n\nLernziele\nIn diesen Baustein lernen Sie …\n\nStatistische Grundbegriffe und Werkzeuge zur grafischen Darstellung\nSensorkennlinien\nKennlinienfehler und deren Korrektur",
    "crumbs": [
      "Methodenbaustein Sensordatenanalyse"
    ]
  },
  {
    "objectID": "skript/einleitung.html",
    "href": "skript/einleitung.html",
    "title": "1  Das Prinzip von Messungen",
    "section": "",
    "text": "1.1 Messung\nto do: Größtfehler ergänzen\nIn diesem Baustein werden die folgenden Module verwendet:\nPhysikalische Größen werden mit der Hilfe von Messgeräten bestimmt. Diese ordnen der tatsächlichen Merkmalsausprägung eine numerische Entsprechung relativ zu einem Bezugssystem zu.\nEin Beispiel: “Johanna ist am Messbrett 173 Zentimeter groß.”\nMesswerte sind aus verschiedenen Gründen Annäherungen an den wahren Wert der zugrundeliegenden physikalischen Größe. Zum einen variiert die Größe eines Menschen im Tagesverlauf. Zum anderen ist das Messergebnis auch ein Ergebnis der verwendeten Skala. Wäre die Messung im imperialen Messsystem erfolgt, wäre Johannas Größe mit 68 Zoll bestimmt worden, was 172,72 Zentimetern entspricht.\nDas Messergebnis ist also keine exakte Entsprechung der tatsächlichen Merkmalsausprägung. Ein bekanntes Beispiel für die mit dem Messvorgang verbundene Unsicherheit ist das Küstenlinienparadox: Das Ergebnis der Vermessung unregelmäßiger Küstenlinien wird umso größer, je kleiner die Messabschnitte gewählt werden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#messung",
    "href": "skript/einleitung.html#messung",
    "title": "1  Das Prinzip von Messungen",
    "section": "",
    "text": "Definition 1.1: Messung\n\n\n\n“Eine Messung ist der experimentelle Vorgang, durch den ein spezieller Wert einer physikalischen Größe als Vielfaches einer Einheit oder eines Bezugswertes ermittelt wird.\nDie Messung ergibt zunächst einen Messwert. Dieser stimmt aber aufgrund störender Einflüsse mit dem wahren Wert der Messgröße praktisch nie überein, sondern weist eine gewisse Messabweichung auf. Zum vollständigen Messergebnis wird der Messwert, wenn er mit quantitativen Aussagen über die zu erwartende Größe der Messabweichung ergänzt wird. Dies wird in der Messtechnik als Teil der Messaufgabe und damit der Messung verstanden.”\nMessung. von verschiedenen Autor:innen steht unter der Lizenz CC BY-SA 4.0 ist abrufbar auf [Wikipedia] (https://de.wikipedia.org/wiki/Messung). 2025\n\nDie ideale Messung ist eine direkte Messung oder der gesuchte Wert hängt linear (direkt?!) vom gemessenen Wert ab.\nDie ideale Messung ist genau und präzise.\n\n\n\n\nDirekte und indirekte Messung\nBei einer direkten Messung wird die Messgröße durch den unmittelbaren Vergleich mit einem Normal oder einem genormten Bezugssystem gewonnen.\n\n\n\n\n\n\n\n\n\nBalkenwaage\n\n\n\n\n\n\n\nZollstock\n\n\n\n\n\n\nAbbildung 1.2: Direkte Messung\n\n\n\nGliedermaßstäbe von Fst76 ist lizensiert unter CC-BY-SA 3.0 und ist abrufbar auf Wikimedia. 2014\n\n \nBei einer indirekten Messung wird die Messgröße auf eine andere pyhsikalische Größe zurückgeführt.\n\n\n\n\n\n\n\n\n\nFederwaage\n\n\n\n\n\n\n\nLaserentfernungsmessung\n\n\n\n\n\n\nAbbildung 1.3: Indirekte Messung\n\n\n\nSpring scale von Amada44 steht unter der Lizenz CC-BY-SA-3.0 unported und ist abrufbar auf Wikimedia. 2016\nObserve the Moon wurde von der NASA veröffentlicht und ist abrufbar unter nasa.gov. 2010\n\n \n\n\nGenauigkeit und Präzision\n\n\n\n\n\n\n\n\nGenauigkeit\n\n\n\n\n\n\n\nPräsizion\n\n\n\n\n\n\nDie Genauigkeit einer Messung ist ein Maß für die Abweichung der Messwerte vom realen Wert. Die Genauigkeit ist nur bestimmbar, wenn anerkannte Referenzwerte vorhanden sind.\n\n\nDie Präzision einer Messung beschreibt, wie gut die einzelnen Messwerte miteinander übereinstimmen. Die Präszision einer Messung wird über die Standardabweichung der Stichprobe bestimmt.\n\n\n\n\nAbbildung 1.4: Genauigkeit und Präzision",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/einleitung.html#messreihen",
    "href": "skript/einleitung.html#messreihen",
    "title": "1  Das Prinzip von Messungen",
    "section": "1.2 Messreihen",
    "text": "1.2 Messreihen\nUm die Unsicherheit einer Messung zu verringern, kann man einen Messwert in Form einer Messreihe wiederholt aufnehmen. Die (erste) beste Schätzung der Messgröße bietet der arithmetische Mittelwert der Messreihe.\nDer arithmetische Mittelwert einer Messreihe \\(\\bar{x}\\) ist die Summe aller Einzelmesswerte dividiert durch die Anzahl der Messwerte \\(N\\).\n\\[\n\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i\n\\]\nMit Hilfe des arithmetischen Mittelwerts kann eine Aussage über die Streuung der Messwerte und die Präzision der Messung getroffen werden. Dazu werden die Varianz und die Standardabweichung der Messreihe berechnet.\n\nVarianzStandardabweichung\n\n\nDie Varianz ist der Mittelwert der quadrierten Abweichungen vom Mittelwert.\n\\[\n\\text{Var}(x_i) = \\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x})^2\n\\]\n\n\nDie Quadratwurzel der Varianz wird als Standardabweichung bezeichnet. Diese hat den Vorteil, dass sie in der Einheit der Messwerte vorliegt und dadurch leichter zu interpretieren ist. Die Standardabweichung \\(s\\) wird so berechnet:\n\\[\ns_{N} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\bar{x})^2}\n\\]\nFür Stichproben wird die Stichprobenvarianz verwendet. Für die Standardabweichung einer Stichprobe gilt:\n\\[\ns_{N-1} = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N}(x_i - \\bar{x})^2}\n\\]\n\n\n\nDa die Varianz das Quadrat der Standardabweichung \\(s\\) ist, wird diese häufig mit \\(s^{2}\\) gekennzeichnet.\n\n\n\n\n\n\nHinweis 1.1: Standardabweichung und Varianz in der Grundgesamtheit\n\n\n\nIn der Stochastik werden Formeln häufig auch mit griechischen Buchstaben geschrieben, wenn Sie sich statt auf eine Stichprobe auf die Grundgesamtheit beziehen.\nDer Mittelwert in der Grundgesamtheit wird auch Erwartungswert genannt und mit dem griechischen Buchstaben \\(\\mu\\) (My) dargestellt. Die Standardabweichung des Erwartungswerts wird mit \\(\\sigma\\) (Sigma) gekennzeichnet. \\[\n\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}(x_i - \\mu)^2}\n\\]\n\n\nMit Hilfe der Standardabweichung kann der Standardfehler der Messung bestimmt werden. Der Standardfehler ist ein Maß dafür, wie genau sich der arithmetische Mittelwert der Stichprobe an den tatsächlichen Mittelwert der Grundgesamtheit, den Erwartungswert, annähert (dazu gleich mehr) und wird auch Stichprobenfehler genannt. Der Standardfehler wird aus der Standardabweichung einer Messung und der Wurzel der Stichprobengröße berechnet. Da die Varianz in der Grundgesamtheit in der Regel unbekannt ist, wird der Standardfehler mit der Stichprobenvarianz geschätzt.\n\\[\n\\sigma_{\\bar{x}} ~ = ~ \\frac{s}{\\sqrt{N}}\n\\]\nDer Standardfehler wird umso kleiner (die Messung umso präziser), je kleiner die Varianz in der Grundgesamtheit und je größer der Stichprobenumfang ist.\nDies lässt sich mit einem simulierten Würfelexperiment verdeutlichen. Bei einem idealen, fairen Würfel kommt jede Augenzahl gleich oft vor. Der Erwartungswert eines sechsseitigen Würfels ist:\n\\[\n\\frac{1}{6} \\sum_{i=1}^{i=6}(x_i) ~ = ~ 3,5\n\\]\nDie Standardabweichung eines fairen, sechsseitigen Würfels beträgt:\n\\[\n\\sqrt{\\frac{1}{6} \\sum_{i=1}^{i=6}(x_i - 3,5)^2} ~ \\approx ~ 1,71\n\\]\nDa die Varianz in der Grundgesamtheit bekannt ist, hängt der Standardfehler des Mittelwerts eines fairen Würfels allein von der Stichprobengröße ab.\n\nExperiment Verteilungskenngrößen\nIn einem simulierten Experiment würfeln 100 Personen jeweils 3, 10 und 50 Mal und bilden den Mittelwert der Augen. Weil ein fairer Würfel simuliert wird, kann der Standardfehler mit der Standardabweichung der Grundgesamtheit berechnet werden.\n\nErgebnissegrafische DarstellungCode\n\n\n\n\nWürfe pro Person: 3             Stichprobengröße: 300\nkleinster Mittelwert: 1.00      größter Mittelwert: 6.00\nStichprobenmittelwert: 3.57     Standardfehler: 0.10\n\nWürfe pro Person: 10            Stichprobengröße: 1000\nkleinster Mittelwert: 1.70      größter Mittelwert: 4.60\nStichprobenmittelwert: 3.49     Standardfehler: 0.05\n\nWürfe pro Person: 50            Stichprobengröße: 5000\nkleinster Mittelwert: 2.98      größter Mittelwert: 4.36\nStichprobenmittelwert: 3.50     Standardfehler: 0.02\n\n\n\nMit zunehmender Anzahl an Würfen nähern sich Minimum und Maximum der individuellen Durchschnittswerte sowie der Stichprobenmittelwert dem Erwartungswert an.\nHinweis: Da das Skript dynamisch generiert wird, wurden die Zufallszahlen von einem festgelegten Startwert aus erzeugt.\n\n\nDie Häufigkeit der individuellen Mittelwerte ist in den folgenden Histogrammen dargestellt.\n\n\n\n\n\n\n\n\n\n\n\nBerechnung\n\npersonen = 100\nstandardabweichung_grundgesamtheit = np.arange(1, 7).std(ddof = 0)\nseed = 1\n\n# 3 Würfe\nwürfe = 3\n\n## Personen stehen in den Zeilen (axis = 0), Würfe in den Spalten (axis = 1)\naugen3 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen3.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen3.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen3.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen3.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\n# 10 Würfe\nwürfe = 10\n\n## Personen stehen in den Zeilen (axis = 0), Würfe in den Spalten (axis = 1)\naugen10 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen10.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen10.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen10.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen10.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\n# 50 Würfe\nwürfe = 50\n\n## Personen stehen in den Zeilen (axis = 1), Würfe in den Spalten (axis = 1)\naugen50 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n## zeilenweise Mittelwert bilden mit np.array.mean(axis = 1)\nprint(f\"Würfe pro Person: {würfe}\\t\\t\\t\",\n      f\"Stichprobengröße: {würfe * personen}\\n\",\n      f\"kleinster Mittelwert: {augen50.mean(axis = 1).min():.2f}\\t\\t\",\n      f\"größter Mittelwert: {augen50.mean(axis = 1).max():.2f}\\n\",\n      f\"Stichprobenmittelwert: {augen50.mean():.2f}\\t\\t\",\n      f\"Standardfehler: {standardabweichung_grundgesamtheit / ( augen50.size ** (1/2) ):.2f}\\n\",\n      sep = \"\")\n\nDarstellung\n\npersonen = 100\nstandardabweichung_grundgesamtheit = np.arange(1, 7).std(ddof = 0)\nseed = 1\n\n# 3 Würfe\nwürfe = 3\naugen3 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# 10 Würfe\nwürfe = 10\naugen10 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# 50 Würfe\nwürfe = 50\naugen50 = np.random.default_rng(seed = seed).integers(low = 1, high = 6, endpoint = True, size = (personen, würfe)) # high is exclusive if endpoint = False\n\n# plotten\nbins = 10\n\n# 3 Würfe\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey = True)\n\nax1.hist(augen3.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax1.set_xlim(1, 6)\nax1.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black', label = 'Erwartungswert')\nax1.set_ylabel('mittleres Würfelergebnis')\nax1.set_ylabel('Häufigkeit Mittelwert')\nax1.set_title(\"3 Würfe pro Person\")\nax1.legend(loc = 'lower left', bbox_to_anchor = (0, -0.2))\n\n# 10 Würfe\nax2.hist(augen10.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax2.set_xlim(1, 6)\nax2.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black')\nax2.set_ylabel('mittleres Würfelergebnis')\nax2.set_title(\"10 Würfe pro Person\")\n\n# 30 Würfe\nax3.hist(augen50.mean(axis = 1), bins = bins, alpha = 0.6, edgecolor = 'black', range = (1, 6))\nax3.set_xlim(1, 6)\nax3.axvline(x = 3.5, ymin = 0, ymax = 1, color = 'black')\nax3.set_ylabel('mittleres Würfelergebnis')\nax3.set_title(\"30 Würfe pro Person\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nAufgabe Verteilungskenngrößen\nIm Datensatz ToothGrowth.csv ist eine Messreihe zur Länge zahnbildender Zellen bei Meerschweinchen gespeichert. Die Tiere erhielten Vitamin C direkt (VC) oder in Form von Orangensaft (OJ) in unterschiedlichen Dosen.\n\n\n\n\n\ndateipfad = \"01-daten/ToothGrowth.csv\"\nmeerschweinchen = pd.read_csv(filepath_or_buffer = dateipfad, sep = ',', header = 0, \\\n  names = ['ID', 'len', 'supp', 'dose'], dtype = {'ID': 'int', 'len': 'float', 'dose': 'float', 'supp': 'category'})\n\n\n\nCode-Block 1.1\n\n\n\nCrampton, E. W. 1947. „THE GROWTH OF THE ODONTOBLASTS OF THE INCISOR TOOTH AS A CRITERION OF THE VITAMIN C INTAKE OF THE GUINEA PIG“. The Journal of Nutrition 33 (5): 491–504. https://doi.org/10.1093/jn/33.5.491\nDer Datensatz kann in R mit dem Befehl “ToothGrowth” aufgerufen werden.\n\n\n\n\n\n\n\n\n\n\n \nBerechnen Sie den arithmetischen Mittelwert, die Varianz, die Standardabweichung und den Stichprobenfehler der Messreihe zur Zahnlänge (len). Verwenden Sie dazu die vorgestellten Formeln.\nDas Ergebnis könnte so aussehen:\n\n\nN: 60\narithmetisches Mittel: 18.81\nStichprobenfehler: 0.99\nStichprobenvarianz: 58.51\nStandardabweichung: 7.65\n\n\n\n\n\n\n\n\nTipp 1.1: Musterlösung Verteilungskenngrößen\n\n\n\n\n\n\ndef verteilungskennwerte(x, output = True):\n\n  # Anzahl Messwerte bestimmen\n  N = len(x)\n\n  # arithmetisches Mittel bestimmen\n  stichprobenmittelwert = sum(x) / N\n\n  # Stichprobenvarianz bestimmen\n  stichprobenvarianz = sum((x - stichprobenmittelwert) ** 2) / (N - 1)\n\n  # Standardabweichung bestimmen\n  standardabweichung = stichprobenvarianz ** (1/2)\n\n  # Stichprobenfehler bestimmen\n  stichprobenfehler = standardabweichung / (N ** (1/2))\n\n  # Ausgabe\n  if output: # output = True\n    print(f\"N: {N}\\n\",\n          f\"arithmetisches Mittel: {stichprobenmittelwert:.2f}\\n\",\n          f\"Stichprobenfehler: {stichprobenfehler:.2f}\\n\",\n          f\"Stichprobenvarianz: {stichprobenvarianz:.2f}\\n\",\n          f\"Standardabweichung: {standardabweichung:.2f}\",\n          sep = '')\n\n  else: # output = False\n    return N, stichprobenmittelwert, stichprobenfehler, stichprobenvarianz, standardabweichung\n\nverteilungskennwerte(meerschweinchen['len'])\n\n\n\n\nDie Module NumPy und Pandas verfügen über eigene Funktionen zur Berechnung der Varianz und der Standardabweichung (siehe folgendes Beispiel).\n\n\nVarianz und Standardabweichung mit NumPy und Pandas\nDie Varianz und Standardabweichung werden mit den Funktion np.var() und np.std() bzw. den Methoden pd.var() und pd.std() berechnet. Der Parameter ddof (delta degrees of freedom) steuert, welcher Nenner zur Berechnung der Varianz verwendet wird in der Form N - ddof. Während der Standardwert in NumPy 0 ist, berechnet Pandas mit dem Standardwert ddof=1 die Stichprobenvarianz.\n\nprint(\"Varianz:\")\nprint(f\"NumPy:\\t{np.var(meerschweinchen['len']):.2f}\")\nprint(f\"Pandas:\\t{meerschweinchen['len'].var():.2f}\")\n\nprint(\"\\nStandardabweichung:\")\nprint(f\"NumPy:\\t{np.std(meerschweinchen['len']):.2f}\")\nprint(f\"Pandas:\\t{meerschweinchen['len'].std():.2f}\")\n\nVarianz:\nNumPy:  57.54\nPandas: 58.51\n\nStandardabweichung:\nNumPy:  7.59\nPandas: 7.65",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Das Prinzip von Messungen</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html",
    "href": "skript/normalverteilung.html",
    "title": "2  Die Normalverteilung",
    "section": "",
    "text": "2.1 Normalverteilung anpassen\nMit zunehmender Stichprobengröße wird eine immer bessere Schätzung des Erwartungswerts erreicht. Mathematisch liegt dieser Beobachtung der zentrale Grenzwertsatz zugrunde. So werden beim Würfeln mit mehreren Würfeln weit vom Erwartungswert entfernte Wurfergebnisse immer unwahrscheinlicher. Dies lässt sich bereits mit wenigen Würfeln zeigen (siehe Beispiel).\nDie mit steigender Stichprobengröße zu beobachtende Annäherung von Messwerten an einen in der Grundgesamtheit geltenden Erwartungswert gilt auch, wenn der Erwartungswert und die Varianz in der Grundgesamtheit unbekannt sind. Mit zunehmender Stichprobengröße nähern sich die Messwerte der Normalverteilung an, die nach ihrem Entdecker Carl Friedrich Gauß auch als Gaußsche Glockenkurve bekannt ist.\nDie für größere Stichproben zu beobachtende Annäherung der Verteilung von Messwerten an die Normalverteilung kann anhand des Gewichts von Pinguinen aus dem Datensatz palmerpenguins gezeigt werden.\nDer Datensatz enthält Daten für drei Pinguinarten.\nUnter anderen wurde das Körpergewicht in Gramm gemessen, das in der Spalte ‘body_mass_g’ eingetragen ist. Die Gewichtsverteilung der drei Spezies wird jeweils mit einem Histogramm dargestellt. Außerdem werden für jede Spezies der Stichprobenmittelwert und die Stichprobenstandardabweichung bestimmt. Mit diesen Werten kann eine Normalverteilungskurve berechnet und in das Histogramm eingezeichnet werden (wie das geht, wird in Beispiel 2.3 gezeigt). So kann optisch geprüft werden, ob die empirische Verteilung der Werte in der Stichprobe einer Normalverteilung mit den selben Werten für Mittelwert und Standardabspreichung entspricht.\nDie Normalverteilung ist eine Dichtekurve, an die sich der Verlauf eines Histogramms mit einer gegen unendlich gehenden Anzahl von Messwerten und einer gegen Null gehenden Klassenbreite annähert.\nDie Dichtefunktion der Normalverteilung beschreibt, welcher Anteil der Werte innerhalb eines bestimmten Wertebereichs liegt. Bei der Berechnung der relativen Häufigkeiten in Beispiel 2.2 haben wir gesehen, dass die Summe der relativen Häufigkeiten 1 ist. Dies entspricht der Fläche unterhalb der Dichtekurve.\nDie Dichtefunktion der Normalverteilung ist definiert als:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} ~ e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n\\]\nDie Form der Normalverteilung ergibt sich aus dem Faktor \\(e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\) der Funktionsgleichung. Das Maximum der Funktion liegt am Punkt \\(x = \\mu\\). Von dort fällt sie symmetrisch ab und nähert sich der x-Achse an. Der Abfall der Funktion erfolgt umso schneller, je kleiner \\(\\sigma\\) ist. Die Wendepunkte der Kurve liegen jeweils eine Standardabweichung vom Mittelwert entfernt.\nEine Normalverteilung mit dem Mittelwert \\(\\mu = 0\\) und einer Standardabweichung \\(\\sigma = 1\\) heißt Standardnormalverteilung.\nUm die Verteilung in einem Datensatz durch eine Normalverteilung anzunähern, werden dessen Mittelwert und Standardabweichung in die Funktionsgleichung der Normalverteilung eingesetzt. Mit Python können die Berechnungen direkt vorgenommen werden. In der Handhabung einfacher sind die vom Paket SciPy bereitgestellten Funktionen, die im nächsten Abschnitt ausführlicher vorgestellt werden. Das folgende Beispiel zeigt die Berechnung und Visualisierung mit Python und mit SciPy.\nQuelle: Skript MB S. 51-54",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#normalverteilung-anpassen",
    "href": "skript/normalverteilung.html#normalverteilung-anpassen",
    "title": "2  Die Normalverteilung",
    "section": "",
    "text": "Beispiel 2.3: Dichtekurven berechnen und darstellen\n\n\n\n\n\nBetrachten wir die Verteilungskennwerte der Gruppe der Meerschweinchen, die eine Dosis von 2 Milligramm Vitamin C erhielten.\n\nprint(verteilungskennwerte(dose2), \"\\n\");\n\ndose2_mean = verteilungskennwerte(dose2, output = False)[1]\ndose2_std = verteilungskennwerte(dose2, output = False)[4]\n\nprint(\"Exakter Mittelwert:\", dose2_mean)\nprint(\"Exakte Standardabweichung:\", dose2_std)\n\nN: 20\narithmetisches Mittel: 26.10\nStichprobenfehler: 0.84\nStichprobenvarianz: 14.24\nStandardabweichung: 3.77\nNone \n\nExakter Mittelwert: 26.1\nExakte Standardabweichung: 3.7741503052098744\n\n\nWenn wir die Standardabweichung und das arithmetische Mittel in die Normalverteilungsfunktion einsetzen, erhalten wir:\n\\[\nf(x) = \\frac{1}{3.7742 \\sqrt{2\\pi}} ~ e^{-\\frac{1}{2}\\left(\\frac{x-26.10}{3.7742}\\right)^2}\n\\]\n\\[\nf(x) = 0.1057 \\times e^{-\\frac{1}{2}\\left(\\frac{x-26.10}{3.7742}\\right)^2}\n\\]\nIn Python können die Berechnungen umgesetzt und grafisch dargestellt werden:\n\n# Histogram der Häufigkeitsdichte zeichnen\nplt.hist(dose2, bins = 7, density = True, edgecolor = 'black', alpha = 0.6);\nplt.title('Länge zahnbildender Zellen bei Meerschweinchen')\n\n# Achsenbeschriftung\nplt.xlabel('Länge der zahnbildenden Zellen (μm)')\nplt.ylabel('Häufigkeitsdichte')\n\n# Normalverteilung berechnen.\nhist, bin_edges = np.histogram(dose2, bins = 7)\n\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\n\n## Normalverteilungsfunktion mit Python berechnen\ny_values =  1 / (dose2_std * np.sqrt(2 * np.pi)) * np.exp(- (x_values - dose2_mean) ** 2 / (2 * dose2_std ** 2))\nplt.plot(x_values, y_values, label = 'Normalverteilung', lw = 4)\n\n## scipy\ny_values_scipy = scipy.stats.norm.pdf(x_values, loc = dose2_mean, scale = dose2_std)\nplt.plot(x_values, y_values_scipy, label = 'SciPy', linestyle = 'dashed')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nDie Verteilung der Länge zahnbildender Zellen bei Meerschweinchen, die eine Dosis von 2 Milligramm Vitamin C erhielten, könnte einer Normalverteilung entsprechen. Aufgrund der geringen Stichprobengröße ist dies aber schwer zu beurteilen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#das-paket-scipy",
    "href": "skript/normalverteilung.html#das-paket-scipy",
    "title": "2  Die Normalverteilung",
    "section": "2.2 Das Paket SciPy",
    "text": "2.2 Das Paket SciPy\nFunktionen zur Berechnung von Dichtekurven können über Paket SciPy importiert werden. Das Modul stats (statistical functions) umfasst zahlreiche Funktionen zum Testen von Hypothesen. Funktionen für die Normalverteilung werden wie folgt aufgerufen:\n\nimport scipy\nprint(\"Häufigkeitsdichte der Normalverteilung bei x = 0:\", scipy.stats.norm.pdf(0), \"\\n\")\n\nHäufigkeitsdichte der Normalverteilung bei x = 0: 0.3989422804014327 \n\n\n\nFür die Normalverteilung sind vier Funktionen relevant:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.pdf(x) berechnet die Dichte der Normalverteilung am Punkt x (PDF = probability density function). x kann auch ein array sein - so wurde die linksstehende Kurve mit dem Befehl scipy.stats.norm.pdf(np.linspace(-4, 4, 100)) berechnet.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.cdf(x) berechnet den Anteil der Werte links von x (CDF = cumulative density function).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.ppf(q) ist die Quantilfunktion der Normalverteilung und die Umkehrfunktion der kumulativen Häufigkeitsdichtefunktion (CDF). Die Funktion berechnet für \\(0 \\le q \\le 1\\) den Wert x, links von dem der Anteil q aller Werte liegt und rechts von dem der Anteil 1-q liegt (PPF = percentile point function).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeschreibung\nDie Funktion scipy.stats.norm.rvs(size) zieht size Zufallszahlen aus der Normalverteilung.\n\n\n\nMit den Parametern loc = mittelwert und scale = standardabweichung kann die Form der Normalverteilung angepasst werden. Standardmäßig wird die Standardnormalverteilung mit loc = 0 und scale = 1 berechnet. Die Parameter der Funktionen können Einzelwerte (Skalare) oder auch Arrays bzw. Listen sein.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#aufgaben-normalverteilung",
    "href": "skript/normalverteilung.html#aufgaben-normalverteilung",
    "title": "2  Die Normalverteilung",
    "section": "2.3 Aufgaben Normalverteilung",
    "text": "2.3 Aufgaben Normalverteilung\nMöglicherweise haben Sie schon einmal von Mensa International gehört, einer Vereinigung für Hochbegabte. Wer Mitglied in dieser Vereinigung werden möchte, soll einen höheren Intelligenzquotienten (IQ) haben als 98 % der Bevölkerung seines:ihres Herkunftslandes (Wikipedia).\n\nWenn der durchschnittliche IQ 100 und die Standardabweichung 15 beträgt, welchen IQ müssten Sie haben, um bei Mensa International aufgenommen zu werden?\nMensa International ist nicht die einzige Organisation ihrer Art, andere Organisationen haben sogar noch strengere Kriterien. Welcher IQ wird benötigt, um hier Mitglied zu werden?\n\n\nIntertel (Kriterium: IQ aus dem höchsten 1 %)\nTriple Nine Society (Kriterium: IQ aus dem höchsten 0,1 %)\nPrometheus Society (Kriterium: IQ aus dem höchsten 0,003 %)\n\n\nDer IQ ist nicht mit angeborener Intelligenz gleichzusetzen und auch abhängig davon, wie viel Gelegenheit man zum Gehirntraining hatte, etwa durch den Schulbesuch. Der niedrigste durchschnittliche IQ wurde mit 71 im Land Niger gemessen. Angenommen Sie hätten einen IQ von 100. Würden Sie in Niger das Kriterium der Mensa International erfüllen?\n\n\n\n\n\n\n\nMusterlösung Normalverteilung\n\n\n\n\n\nAufgabe 1: Einen IQ von mehr als …\n\nprint(scipy.stats.norm.ppf(loc = 100, scale = 15, q = 0.98))\n\n130.80623365947733\n\n\nAufgabe 2: Sie benötigen einen IQ von mindestens…\n\nprint(scipy.stats.norm.ppf(loc = 100, scale = 15, q = 0.99))\nprint(scipy.stats.norm.ppf(loc = 100, scale = 15, q = 0.999))\nprint(scipy.stats.norm.ppf(loc = 100, scale = 15, q = 1 - (0.003 / 100)))\n\n134.8952181106126\n146.3534845925172\n160.19216216677682\n\n\nAufgabe 3: Nicht ganz.\n\nprint(scipy.stats.norm.cdf(loc = 71, scale = 15, x = 100))\n\n0.9734024259789904\n\n\n\n\n\nÜbrigens: Wie der Spiegel berichtet, schneiden Studierende mit mittelmäßigem Intelligenzquotienten ebenso erfolgreich ab wie Hochbegabte, vorausgesetzt sie sind neugierig genug und arbeiten gewissenhaft.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#konfidenzintervalle",
    "href": "skript/normalverteilung.html#konfidenzintervalle",
    "title": "2  Die Normalverteilung",
    "section": "2.4 Konfidenzintervalle",
    "text": "2.4 Konfidenzintervalle\nDie Grundidee in der Statistik ist, dass von Stichprobenwerten auf den tatsächlichen Wert in der Grundgesamtheit geschlossen werden kann. Die Überlegung ist wie folgt:\n\nWenn eine Stichprobe aus einer Grundgesamtheit gezogen wird, dann streuen die Stichprobenwerte normalverteilt um den Mittelwert der Grundgesamtheit. Bei einer Normalverteilung liegen\n\n68,27 % aller Werte im Intervall \\(\\pm 1 ~ s\\),\n95,45 % aller Werte im Intervall \\(\\pm 2 ~ s\\) und\n99,73 % aller Werte im Intervall \\(\\pm 3 ~ s\\).\n\nMit der gleichen Wahrscheinlichkeitsverteilung liegt der unbekannte Mittelwert der Grundgesamtheit um einen zufälligen Wert aus der Stichprobe.\nDer Erwartungswert kann mit einer gewissen Wahrscheinlichkeit aus dem Standardfehler des Mittelwerts einer Stichprobe geschätzt werden. Man wählt dazu ein Konfidenzniveau, also eine Vertrauenswahrscheinlichkeit, dass der Erwartungswert tatsächlich im Bereich der Schätzung liegt. Der umgekehrte Fall, dass der Erwartungswert nicht im Bereich der Schätzung liegt, wird Signifikanz- oder Alphaniveau genannt und mit dem griechischen Buchstaben \\(\\alpha\\) (alpha) gekennzeichnet. \\(\\alpha\\) liegt im Bereich 0 - 1, das Konfidenzniveau ist \\(1 - \\alpha\\) (siehe: Fehler 1. und 2. Art).\n\nder Erwartungswert liegt in 68,27 % aller Fälle im Intervall \\(\\pm 1 ~ \\frac{s}{\\sqrt{n}}\\),\nder Erwartungswert liegt in 95,45 % aller Fälle im Intervall \\(\\pm 2 ~ \\frac{s}{\\sqrt{n}}\\) und\nder Erwartungswert liegt in 99,73 % aller Fälle im Intervall \\(\\pm 3 ~ \\frac{s}{\\sqrt{n}}\\).\n\n\nHäufig wird das Alphaniveau \\(\\alpha = 0.05\\) bzw. das Konfidenzintervall 95 % gewählt, was \\(\\pm 1.96 ~ \\frac{s}{\\sqrt{n}}\\) entspricht. Dies gilt aber nur für große Stichproben. Für kleine Stichprobengrößen folgen die Stichprobenmittelwerte der t-Verteilung, die im nächsten Abschnitt vorgestellt wird.\nhier könnte / müsste man noch einseitige und zweiseitige Hypothesentests und den Begriff “Alpha-Halbe” einführen. Das ließe sich auch gut grafisch mit nur nach rechts gehenden und beidseitigen Pfeilen darstellen.\nIm folgenden Beispiel wird die Idee, dass mit einer gewissen Wahrscheinlichkeit vom Stichprobenmittelwert auf den Mittelwert der Grundgesamtheit (Erwartungswert) geschlossen werden kann, noch einmal grafisch dargestellt.\n\n\n\n\n\n\nBeispiel 2.4: Prinzip der schließenden Statistik\n\n\n\n\n\n\nStandardnormalverteilungEinzelner MesswertStichprobe N = 12Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEin Stichprobenmittelwert streut inform einer Normalverteilungskurve mit sigma = stichprobenfehler. Diese Dichtekurve ist erheblich schmaler und höher als die Normalverteilungskurve eines einzelnen Messwerts. Dies liegt an der geringen Standardabweichung in der Stichprobe von ~ 0.2, was die Kurve staucht.\n\n\nCode für das Panel Stichprobe N = 12\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\n\n# Parameter der Standardnormalverteilung\nmu, sigma = 0, 1  # Mittelwert und Standardabweichung\n\n# Daten generieren\nseed = 4\nnp.random.seed(seed = seed)\ndata = np.random.default_rng().normal(mu, sigma, 1000)\n\n# Grafik\nplt.figure(figsize = (8.5, 6))\n\n# Histogramm plotten\narray, bins, patches = plt.hist(data, bins = 30, density = True, alpha = 0.6, color = 'lightgoldenrodyellow', edgecolor='black')\n\n# Mittelwert einzeichnen\nmean_line = plt.axvline(mu, color = 'steelblue', linestyle = 'solid', linewidth = 3)\n\n# positive und negative Standardabweichungen einzeichnen\npos_std_lines = [plt.axvline(mu + i * sigma, color = 'steelblue', linestyle = 'dotted', linewidth = 2) for i in range(1, 4)]\nneg_std_lines = [plt.axvline(mu - i * sigma, color = 'steelblue', linestyle = 'dotted', linewidth = 2) for i in range(1, 4)]\n\n# Normalverteilungskurve\nx_values = np.linspace(min(bins), max(bins), 100)\ny_values = 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(- (x_values - mu) ** 2 / (2 * sigma ** 2))\nnormal_dist_curve = plt.plot(x_values, y_values, color = 'steelblue', linestyle = 'solid', linewidth = 2)\n\n# Stichprobe\nN = 12\nnp.random.seed(seed = 4)\nstichprobe = np.random.default_rng().normal(mu, sigma, N)\n\nstichprobenstandardabweichung = stichprobe.std(ddof = 1)\nstichprobenmittelwert = stichprobe.mean()\nstandardfehler =  stichprobenstandardabweichung / np.sqrt(len(stichprobe))\n\n# Histogramm berechnen\n# hist, bins = np.histogram(stichprobe, bins = 30, density = True)\n\n# Standardfehlerkurve Stichprobe\n# x_values = np.linspace(min(bins), max(bins), 100)\nx = np.linspace(stichprobenmittelwert - 4 * stichprobenstandardabweichung, stichprobenmittelwert + 4 * stichprobenstandardabweichung, 100)\ny_values = scipy.stats.t.pdf(x = x_values, df = N - 1, loc = stichprobenmittelwert, scale = standardfehler) # t-Verteilung\n\n# Stichprobenmittelwert einzeichnen\nmean_stichprobe = plt.axvline(stichprobenmittelwert, color = 'black', linestyle = 'solid', linewidth = 2)\n\n# Verteilungskurve einzeichnen\nstichprobe_dist_curve = plt.plot(x_values, y_values, color = 'black', linestyle = 'solid', linewidth = 2)\n\n# Legende\nplt.legend([normal_dist_curve[0], mean_line, neg_std_lines[0], mean_stichprobe, stichprobe_dist_curve[0]],\n           ['Standardnormalverteilung', 'Mittelwert', 'Standardabweichung', 'Stichprobenmittelwert', 't-Verteilung'],\n           loc='upper right', handlelength = 3)\n\nplt.title('Standardnormalverteilung')\nplt.xlabel('Standardabweichung')\nplt.ylabel('Häufigkeitsdichte')\n\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#die-t-verteilung",
    "href": "skript/normalverteilung.html#die-t-verteilung",
    "title": "2  Die Normalverteilung",
    "section": "2.5 Die t-Verteilung",
    "text": "2.5 Die t-Verteilung\nDie t-Verteilung wurde von William Sealy Gosset entdeckt (wenngleich nicht als erstem) und popularisiert. Die Verteilung ist auch als Student’sche Verteilung bekannt: Da Gossets Arbeitgeber, die Guiness-Brauerei, die Veröffentlichung der Entdeckung nicht gestattete, publizierte Gosset unter dem Synonym Student. (Wikipedia)\nDie t-Verteilung beschreibt die Verteilung von Stichprobenmittelwerten mit unbekannter Varianz in der Grundgesamtheit, deren Standardfehler mit der Stichprobenstandardabweichung geschätzt wird. Die t-Verteilung hat gegenüber der Normalverteilung die Anzahl der Freiheitsgrade als zusätzlichen Parameter\n\n\n\n\n\n\nDefinition 2.2: Anzahl Freiheitsgrade\n\n\n\n\n\n“Die Anzahl unabhängiger Information, die in die Schätzung eines Parameters einfließen, wird als Anzahl der Freiheitsgrade bezeichnet. Im Allgemeinen sind die Freiheitsgrade einer Schätzung eines Parameters gleich der Anzahl unabhängiger Einzelinformationen, die in die Schätzung einfließen, abzüglich der Anzahl der zu schätzenden Parameter, die als Zwischenschritte bei der Schätzung des Parameters selbst verwendet werden. Beispielsweise fließen \\(n\\) Werte in die Berechnung der Stichprobenvarianz ein. Dennoch lautet die Anzahl der Freiheitsgrade \\(n − 1\\), da als Zwischenschritt der Mittelwert geschätzt wird und somit ein Freiheitsgrad verloren geht.”\nAnzahl der Freiheitsgrade (Statistik). von verschiedenen Autor:innen steht unter der Lizenz CC BY-SA 4.0 ist abrufbar auf Wikipedia. 2025\n\n\n\nDie allgemeine Häufigkeitsdichtefunktion der t-Verteilung lautet:\n\\[\nf(x) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\nu \\pi} , \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{x^2}{\\nu}\\right)^{-\\frac{\\nu + 1}{2}}\n\\]\n\n\\(\\nu\\) (ny) ist die Anzahl der Freiheitsgrade.\n\\(\\Gamma\\) ist die Gammafunktion, die für ganzzahlige Argumente \\(n\\) den Wert \\(\\Gamma(n) = (n-1)!\\) hat.\n\nDa für die Berechnung des Stichprobenmittelwerts die Anzahl der Freiheitsgrade \\(n - 1\\) ist, kann auch geschrieben werden: \\[\nf(x) = \\frac{\\Gamma\\left(\\frac{n}{2}\\right)}{\\sqrt{(n-1) \\pi} , \\Gamma\\left(\\frac{n-1}{2}\\right)} \\left(1 + \\frac{x^2}{n-1}\\right)^{-\\frac{n}{2}}\n\\]\n\n\\(n\\) ist die Stichprobengröße.\n\nDas Modul scipy.stats stellt Funktionen zur Berechnung der t-Verteilung bereit.\n\nscipy.stats.t.pdf(x, df, loc=0, scale=1) berechnet die Häufigkeitsdichte für die Werte x für eine t-Verteilung mit df Freiheitsgraden, Mittelwert loc und Standardabweichung scale (PDF = probability density function).\nscipy.stats.t.cdf(x, df, loc=0, scale=1) berechnet den Anteil der Werte links von x (CDF = cumulative density function).\nscipy.stats.t.ppf(q, df, loc=0, scale=1) ist die Quantilfunktion der t-Verteilung (PPF = percentile point function).\nscipy.stats.t.rvs(df, loc=0, scale=1, size=1) zieht size Zufallzahlen aus der t-Verteilung.\n\nDie Parameter der Funktionen können Einzelwerte (Skalare) oder auch Arrays bzw. Listen sein.\nMit zunehmender Stichprobengröße nähert sich die t-Verteilung der Normalverteilung an. Als Faustformel gilt \\(n &gt; 30\\). Untenstehende Grafik zeigt die Annäherung der t-Verteilung an die Normalverteilung.\n\nGrafikCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_values = np.linspace(-4, 4, 100)\n\n# Normalverteilung\ny_values = scipy.stats.norm.pdf(x_values)\nplt.plot(x_values, y_values, color = 'black', lw = 3, label = 'Normalverteilung')\n# plt.ylim(bottom = 0, top = 0.5)\n\n# t-Verteilungen\nmarker = [\".\", \"1\", \"x\"]\n\n[plt.plot(x_values, scipy.stats.t.pdf(x_values, df = (i + (i - 1) * 2)), linestyle = 'dotted', marker = marker[i - 1] , linewidth = 2, alpha = 0.6, label = 'df = ' + str((i + (i - 1) * 2))) for i in range(1, 4)]\n\nplt.suptitle('Das Argument df der t-Verteilung')\nplt.xlabel('Standardabweichung')\nplt.ylabel('Häufigkeitsdichte')\nplt.legend(loc = 'upper left')\nplt.show()\n\n\n\n\nDas Maximum der t-Verteilung ist weniger dicht, dafür sind die Ränder der Verteilung dichter als die Normalverteilung.\nSomit gilt für die t-Verteilung von Stichprobenmittelwerten:\n\\[\n\\bar{x} \\pm t_{n-1} \\cdot \\frac{s}{\\sqrt{n}}\n\\]\n\n\\(t\\) ist der Rückgabewert der Funktion scipy.stats.t.ppf(q, df = n - 1, loc = 0, scale = 1)\nq ist das gewählte Alphaniveau bzw. für einen zweiseitigen Hypothesentest \\(\\frac{\\alpha}{2}\\) und \\(1 - \\frac{\\alpha}{2}\\).\nDas Ergebnis ist der Rückgabewert der Funktionen:\n\nscipy.stats.t.ppf(q = alpha/2, df = n - 1, loc = stichprobenmittelwert, scale = stichprobenstandardfehler)\nscipy.stats.t.ppf(q = 1 - alpha/2, df = n - 1, loc = stichprobenmittelwert, scale = stichprobenstandardfehler)\n\n\nDie t-Verteilung des geschätzten Stichprobenmittelwerts für kleine Stichproben wird für im Jahr 2008 beobachtete weibliche Pinguine dargestellt.\n\nprint(penguins.groupby(by = [penguins['species'], penguins['sex'], penguins['year']]).size())\n\nspecies    sex     year\nAdelie     female  2007    22\n                   2008    25\n                   2009    26\n           male    2007    22\n                   2008    25\n                   2009    26\nChinstrap  female  2007    13\n                   2008     9\n                   2009    12\n           male    2007    13\n                   2008     9\n                   2009    12\nGentoo     female  2007    16\n                   2008    22\n                   2009    20\n           male    2007    17\n                   2008    23\n                   2009    21\ndtype: int64\n\n\n\nGrafikCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear = 2008\nsex = 'female'\nspecies = 'Adelie'\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (7.5, 6), sharey = True, layout = 'tight')\nplt.suptitle('Gewichtsverteilung von weiblichen Pinguinen im Jahr 2008')\n\n# Adelie\ndata = penguins['body_mass_g'][(penguins['species'] == species) & (penguins['sex'] == sex) & (penguins['year'] == year)]\nstichprobengröße = data.size\n\n## Histogramm\nax1.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C0', density = True)\nax1.set_xlabel('Gewicht in Gramm')\nax1.set_ylabel('Häufigkeitsdichte')\nax1.set_title(label = str(species) + \" N = \" + str(stichprobengröße))\n\n## t-Verteilung des Stichprobenmittelwerts\nstichprobenmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nstandardfehler = stichprobenstandardabweichung / np.sqrt(stichprobengröße)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values = scipy.stats.t.pdf(x_values, loc = stichprobenmittelwert, scale = standardfehler, df = stichprobengröße - 1)\n\nax1.plot(x_values, y_values, color = 'black', linewidth = 1, label = 't-Verteilung')\nax1.legend(loc = 'upper left')\n\n# Chinstrap\nspecies = 'Chinstrap'\n\ndata = penguins['body_mass_g'][(penguins['species'] == species) & (penguins['sex'] == sex) & (penguins['year'] == year)]\nstichprobengröße = data.size\n\n## Histogramm\nax2.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C1', density = True)\nax2.set_xlabel('Gewicht in Gramm')\nax2.set_title(label = str(species) + \" N = \" + str(stichprobengröße))\n\n## t-Verteilung des Stichprobenmittelwerts\nstichprobenmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nstandardfehler = stichprobenstandardabweichung / np.sqrt(stichprobengröße)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values = scipy.stats.t.pdf(x_values, loc = stichprobenmittelwert, scale = standardfehler, df = stichprobengröße - 1)\n\nax2.plot(x_values, y_values, color = 'black', linewidth = 1)\n\n# Gentoo\nspecies = 'Gentoo'\n\ndata = penguins['body_mass_g'][(penguins['species'] == species) & (penguins['sex'] == sex) & (penguins['year'] == year)]\nstichprobengröße = data.size\n\n## Histogramm\nax3.hist(data, alpha = 0.6, edgecolor = 'lightgrey', color = 'C2', density = True)\nax3.set_xlabel('Gewicht in Gramm')\nax3.set_title(label = str(species) + \" N = \" + str(stichprobengröße))\n\n## t-Verteilung des Stichprobenmittelwerts\nstichprobenmittelwert = data.mean()\nstichprobenstandardabweichung = data.std(ddof = 1)\nstandardfehler = stichprobenstandardabweichung / np.sqrt(stichprobengröße)\nhist, bin_edges = np.histogram(data)\nx_values = np.linspace(min(bin_edges), max(bin_edges), 100)\ny_values = scipy.stats.t.pdf(x_values, loc = stichprobenmittelwert, scale = standardfehler, df = stichprobengröße - 1)\n\nax3.plot(x_values, y_values, color = 'black', linewidth = 1)\n\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/normalverteilung.html#aufgabe-konfidenzintervalle",
    "href": "skript/normalverteilung.html#aufgabe-konfidenzintervalle",
    "title": "2  Die Normalverteilung",
    "section": "2.6 Aufgabe Konfidenzintervalle",
    "text": "2.6 Aufgabe Konfidenzintervalle\n\nSchätzen Sie das Gewicht für im Jahr 2008 beobachtete weibliche Pinguine der Spezies Adelie, Chinstrap und Gentoo.\nWelches Konfidenzintervall können Sie für die Mittelwerte angeben, wenn eine Vertrauenswahrscheinlichkeit von 90 % gelten soll?\n\n\n\n\n\n\n\nTipp 2.1: Tipp und Musterlösung\n\n\n\n\n\nFolgende Schritte helfen Ihnen bei der Lösung:\n\nBestimmen Sie den Stichprobenmittelwert \\(\\bar{x}\\).\nBestimmen Sie die Stichprobenstandardabweichung \\(s\\), die Stichprobengröße \\(N\\) und den Standardfehler \\(\\frac{s}{\\sqrt{N}}\\).\nBestimmen Sie die z- oder t-Werte der Normal- bzw. t-Verteilung für das gewählte Konfidenzniveau - für einen zweiseitigen Hypothesentest \\(\\frac{\\alpha}{2}\\) und \\(1 - \\frac{\\alpha}{2}\\)\nBerechnen Sie das Konfidenzintervall \\(\\bar{x} \\pm t_{\\alpha / 2} ~ \\frac{s}{\\sqrt{n}}\\).\n\n\n\n\n\n\n\nMusterlösung\n\n\n\n\n\nAlphaniveau definieren und Pinguine auswählen\n\nalpha = 1 - 0.9\ndata = penguins[(penguins['sex'] == sex) & (penguins['year'] == year)]\n\n\nStichprobenmittelwerte bestimmen.\n\n\npenguin_means = data['body_mass_g'].groupby(by = data['species']).mean()\nprint(penguin_means)\n\nspecies\nAdelie       3386.000000\nChinstrap    3472.222222\nGentoo       4627.272727\nName: body_mass_g, dtype: float64\n\n\n\nStichprobenstandardabweichung, Stichprobengröße und Standardfehler bestimmen.\n\n\npenguin_stds = data['body_mass_g'].groupby(by = data['species']).std(ddof = 1)\npenguin_sizes = data['body_mass_g'].groupby(by = data['species']).size()\npenguin_stderrors = penguin_stds / np.sqrt(penguin_sizes)\n\nprint(\"Stichprobenstandardabweichungen:\\n\", penguin_stds)\nprint(\"\\nStichprobengrößen:\\n\", penguin_sizes)\nprint(\"\\nStandardfehler:\\n\", penguin_stderrors)\n\nStichprobenstandardabweichungen:\n species\nAdelie       288.862712\nChinstrap    370.903551\nGentoo       339.722321\nName: body_mass_g, dtype: float64\n\nStichprobengrößen:\n species\nAdelie       25\nChinstrap     9\nGentoo       22\nName: body_mass_g, dtype: int64\n\nStandardfehler:\n species\nAdelie        57.772542\nChinstrap    123.634517\nGentoo        72.429042\nName: body_mass_g, dtype: float64\n\n\n\nt-Werte bestimmen\n\n\nt_unten = scipy.stats.t.ppf(alpha / 2, loc = 0, scale = 1, df = penguin_sizes - 1)\nprint(\"t-Wert untere Intervallgrenze:\", t_unten)\n\nt_oben = scipy.stats.t.ppf(1 - alpha / 2, loc = 0, scale = 1, df = penguin_sizes - 1)\nprint(\"t-Wert obere Intervallgrenze:\", t_oben)\n\nt-Wert untere Intervallgrenze: [-1.71088208 -1.85954804 -1.7207429 ]\nt-Wert obere Intervallgrenze: [1.71088208 1.85954804 1.7207429 ]\n\n\n\nKonfidenzintervall bestimmen\n\n\n# mit scipy.stats.t.ppf\nuntere_intervalle = scipy.stats.t.ppf(alpha / 2, loc = penguin_means, scale = penguin_stderrors, df = penguin_sizes - 1)\nprint(\"untere Intervallgrenzen:\", untere_intervalle)\n\nobere_intervalle = scipy.stats.t.ppf(1 - alpha / 2, loc = penguin_means, scale = penguin_stderrors, df = penguin_sizes - 1)\nprint(\"obere Intervallgrenzen:\", obere_intervalle)\n\nprint(\"\\n'manuelle' Berechnung:\\n\")\n# 'manuell'\nprint(penguin_means + t_unten * penguin_stderrors)\nprint(penguin_means + t_oben * penguin_stderrors)\n\nuntere Intervallgrenzen: [3287.15799233 3242.31789851 4502.64096694]\nobere Intervallgrenzen: [3484.84200767 3702.12654593 4751.90448761]\n\n'manuelle' Berechnung:\n\nspecies\nAdelie       3287.157992\nChinstrap    3242.317899\nGentoo       4502.640967\nName: body_mass_g, dtype: float64\nspecies\nAdelie       3484.842008\nChinstrap    3702.126546\nGentoo       4751.904488\nName: body_mass_g, dtype: float64",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Die Normalverteilung</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html",
    "href": "skript/hooke.html",
    "title": "3  Lineare Parameterschätzung",
    "section": "",
    "text": "3.1 Messreihe Hooke’sches Gesetz\nGeht es in diesem Kapitel überhaupt um Kennlinien? Lineare Parameterschätzung?!\nMögliche Quellen:\nDas Hooke’sche Gesetz, benannt nach dem englischen Wissenschaftler Robert Hooke, beschreibt die Beziehung zwischen der Kraft \\(F\\) und der Längenänderung \\(\\Delta{x}\\) einer Feder durch die Gleichung \\(F = k \\times \\Delta{x}\\), wobei \\(k\\) die Federkonstante ist.\nDie Federkonstante ist eine grundlegende Eigenschaft elastischer Materialien und gibt an, wie viel Kraft erforderlich ist, um eine Feder um eine bestimmte Länge zu dehnen oder zu komprimieren. Das Hooke’sche Gesetz besagt, dass die Deformation eines elastischen Körpers proportional zur aufgebrachten Kraft ist, solange die Feder nicht über den elastischen Bereich hinaus gedehnt oder gestaucht wird.\nIn einem Experiment wurde das Hooke’sche Gesetz überprüft. An einer an einer Halterung hängenden Metallfeder ist ein (variables) Gewicht angebracht. Darunter befindet sich in einigem Abstand ein Ultraschallsensor zur Abstandsmessung. Der Abstand zwischen der Unterseite des an der Feder befestigten Gewichts und dem Ultraschallsensor ist der gemessene Abstand.\nDie Gewichte konnten mit einer Genauigkeit von \\(\\epsilon_{m} = 0,5 g\\) mit einer Küchenwaage bestimmt werden.\nDie Messreihe liegt in Form einer CSV-Datei unter dem Pfad ‘01-daten/hooke_data.csv’ vor. Die Datei wird mit Pandas eingelesen.\ndateipfad = \"01-daten/hooke_data.csv\"\nhooke = pd.read_csv(filepath_or_buffer = dateipfad, sep = ';')",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Parameterschätzung</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html#messreihe-hookesches-gesetz",
    "href": "skript/hooke.html#messreihe-hookesches-gesetz",
    "title": "3  Lineare Parameterschätzung",
    "section": "",
    "text": "Versuchsaufbau\n\n\n\n\n\nDeskriptive Statistik\nNach dem Einlesen sollte man sich einen Überblick über die Daten verschaffen. Mit den Methoden pd.DataFrame.head() und pd.DataFrame.tail() kann ein Ausschnitt vom Beginn und vom Ende der Daten betrachtet werden.\n\nprint(hooke.head(), \"\\n\")\nprint(hooke.tail())\n\n   no  mass  distance\n0   0   705    153.29\n1   1   705    152.74\n2   2   705    153.27\n3   3   705    152.81\n4   4   705    152.77 \n\n      no  mass  distance\n109  109     0    173.70\n110  110     0    173.44\n111  111     0    173.75\n112  112     0    173.30\n113  113     0    200.00\n\n\nDie Methode pd.DataFrame.describe() erstellt die deskriptive Statistik für den Datensatz. Diese ist in diesem Fall jedoch noch nicht sonderlich nützlich. Die Spalte ‘no’ enthält lediglich eine laufende Versuchsnummer, die Spalte ‘mass’ enhält verschiedene Gewichte.\n\nhooke.describe()\n\n\n\n\n\n\n\n\nno\nmass\ndistance\n\n\n\n\ncount\n114.000000\n114.000000\n114.000000\n\n\nmean\n56.561404\n394.921053\n162.301754\n\n\nstd\n33.131552\n226.237605\n7.483767\n\n\nmin\n0.000000\n0.000000\n152.740000\n\n\n25%\n28.250000\n201.000000\n156.622500\n\n\n50%\n56.500000\n452.000000\n160.720000\n\n\n75%\n84.750000\n605.000000\n167.767500\n\n\nmax\n113.000000\n705.000000\n200.000000\n\n\n\n\n\n\n\n \nSinnvoller ist eine nach dem verwendeten Gewicht aufgeteilte beschreibende Statistik der gemessenen Ausdehnung. Dafür kann die Pandas-Methode pd.DataFrame.groupby() verwendet werden. So kann für jedes der gemessenen Gewichte der arithmethische Mittelwert und die Standardabweichung abgelesen werden.\n\nhooke.groupby(by = 'mass')['distance'].describe()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nmass\n\n\n\n\n\n\n\n\n\n\n\n\n0\n12.0\n175.828333\n7.620157\n173.27\n173.3150\n173.570\n174.1125\n200.00\n\n\n100\n11.0\n171.044545\n0.985833\n170.15\n170.3650\n170.800\n171.2400\n173.56\n\n\n201\n11.0\n167.791818\n0.296305\n167.26\n167.7200\n167.780\n167.9750\n168.19\n\n\n301\n10.0\n163.710000\n1.660977\n161.60\n162.0575\n163.825\n165.3250\n165.86\n\n\n401\n10.0\n161.967000\n0.313229\n161.42\n161.8450\n161.915\n162.0250\n162.48\n\n\n452\n10.0\n160.713000\n0.627854\n159.98\n160.4575\n160.555\n160.7400\n161.83\n\n\n503\n10.0\n159.314000\n0.781099\n158.43\n158.6400\n159.220\n159.9650\n160.61\n\n\n554\n10.0\n157.547000\n0.523791\n156.92\n157.2075\n157.435\n157.7100\n158.60\n\n\n605\n10.0\n156.142000\n0.354206\n155.62\n156.0700\n156.080\n156.2075\n156.84\n\n\n655\n11.0\n154.022727\n0.224414\n153.72\n153.8800\n153.920\n154.2400\n154.35\n\n\n705\n9.0\n153.008889\n0.241425\n152.74\n152.8100\n152.910\n153.2700\n153.29\n\n\n\n\n\n\n\n \nBereits an dieser Stelle könnte die hohe Standardabweichung in der Messreihe mit 0 Gramm auffallen. Leichter ist es jedoch in der grafischen Betrachtung.\n\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = \"Messreihe Hooke`sches Gesetz\", ylabel = 'Abstand in cm', xlabel = 'Gewicht in Gramm')\n\n\n\n\n\n\n\n\n \nGrafisch fällt der Messwert von 200 cm für das Gewicht 0 Gramm als stark von den übrigen Messwerten abweichend auf.\nDie Messwerte für das Gewicht 0 Gramm sollen näher betrachtet werden. Dafür werden die Messwerte sowohl absolut, als auch standardisiert in Einheiten der Standardabweichung (z-Werten) ausgedrückt ausgegeben.\nEine Variable wird standardisiert, indem von jedem Wert der Erwartungswert abgezogen und das Ergebnis durch die Standardabweichung geteilt wird.\n\\[\nZ = \\frac{x - \\mu}{\\sigma}\n\\]\nDa in der Regel der Erwartungswert und die Standardabweichung unbekannt sind, werden der Stichprobenmittelwert und die Stichprobenstandardabweichung verwendet. Dies nennt man Studentisieren, nach dem Pseudonym bereits im vorherigen Kapitel erwähnten William Sealy Gosset.\n\\[\nz_{i} = \\frac{x_{i} - \\bar{x}}{s}\n\\]\n\ngewicht = 0\n\n# z-Transformation manuell berechnen\nmittelwert_ausdehnung = hooke[hooke['mass'] == gewicht].loc[: , 'distance'].mean()\nstandardabweichung_ausdehnung = hooke[hooke['mass'] == gewicht].loc[: , 'distance'].std(ddof = 1)\n\nz_values = hooke[hooke['mass'] == gewicht].loc[: , 'distance'].apply(lambda x: ( (x - mittelwert_ausdehnung) /standardabweichung_ausdehnung))\nz_values.name = 'z-values'\n\n# z-Transformation mit scipy\nscipy_z_values = scipy.stats.zscore(hooke[hooke['mass'] == gewicht].loc[: , 'distance'], ddof = 1)\nprint(type(scipy_z_values))\nscipy_z_values.name = 'scipy z-values'\n\n# gemeinsame Ausgabe der Daten\nprint(pd.concat([hooke[hooke['mass'] == gewicht], z_values, scipy_z_values], axis = 1))\n\n&lt;class 'pandas.core.series.Series'&gt;\n      no  mass  distance  z-values  scipy z-values\n102  102     0    173.32 -0.329171       -0.329171\n103  103     0    174.11 -0.225498       -0.225498\n104  104     0    173.42 -0.316048       -0.316048\n105  105     0    174.12 -0.224186       -0.224186\n106  106     0    173.30 -0.331795       -0.331795\n107  107     0    174.21 -0.212375       -0.212375\n108  108     0    173.27 -0.335732       -0.335732\n109  109     0    173.70 -0.279303       -0.279303\n110  110     0    173.44 -0.313423       -0.313423\n111  111     0    173.75 -0.272742       -0.272742\n112  112     0    173.30 -0.331795       -0.331795\n113  113     0    200.00  3.172069        3.172069\n\n\nDer Wert 200 cm in Zeile 113 scheint fehlerhaft zu sein. Eine Eigendehnung der Feder um zusätzliche 16 Zentimeter ist nicht plausibel. Auch der z-Wert &gt; 3 kennzeichnet den Messwert als Ausreißer. Die Zeile wird deshalb aus dem Datensatz entfernt.\n\n\n\n\n\n\nDefinition 3.1: Ausreißer\n\n\n\n\n\nIn der Statistik wird ein Messwert als Ausreißer bezeichnet, wenn dieser stark von der übrigen Messreihe abweicht. In einer Messreihe können auch mehrere Ausreißer auftreten. Diese Werte können zur Verbesserung der Schätzung aus der Messreihe entfernt werden, wenn anzunehmen ist, dass diese durch Messfehler und andere Störgrößen verursacht sind.\nEine Möglichkeit, Ausreißer zu identifizieren, ist die z-Transformation. Dabei muss ein Schwellenwert gewählt werden, ab dem ein Messwert als Ausreißer klassifiziert werden soll, bspw. 2,5 oder 3 Einheiten der Standardabweichung. In der Statistik wurde eine ganze Reihe von Ausreißertests entwickelt (siehe Ausreißertests)\nDie Einstufung eines Messwerts als Ausreißer kann aber nicht allein auf der Grundlage statistischer Verfahren erfolgen, sondern ist immer eine Ermessensentscheidung auf der Grundlage Ihres Fachwissens. Denn nicht alle abweichenden Werte sind automatisch ungültig, sondern treten mit einer gewissen statistischen Wahrscheinlichkeit auf (siehe Kapitel Normalverteilung). Man spricht dann von gültigen Extremwerten.\nAusreißer von verschiedenen Autor:innen steht unter der Lizenz CC BY-SA 4.0 und ist abrufbar auf Wikipedia\n\n\n\n\nhooke.drop(index = 113, inplace = True)\n\nhooke.groupby(by = 'mass')['distance'].describe()\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nmass\n\n\n\n\n\n\n\n\n\n\n\n\n0\n11.0\n173.630909\n0.367409\n173.27\n173.3100\n173.440\n173.9300\n174.21\n\n\n100\n11.0\n171.044545\n0.985833\n170.15\n170.3650\n170.800\n171.2400\n173.56\n\n\n201\n11.0\n167.791818\n0.296305\n167.26\n167.7200\n167.780\n167.9750\n168.19\n\n\n301\n10.0\n163.710000\n1.660977\n161.60\n162.0575\n163.825\n165.3250\n165.86\n\n\n401\n10.0\n161.967000\n0.313229\n161.42\n161.8450\n161.915\n162.0250\n162.48\n\n\n452\n10.0\n160.713000\n0.627854\n159.98\n160.4575\n160.555\n160.7400\n161.83\n\n\n503\n10.0\n159.314000\n0.781099\n158.43\n158.6400\n159.220\n159.9650\n160.61\n\n\n554\n10.0\n157.547000\n0.523791\n156.92\n157.2075\n157.435\n157.7100\n158.60\n\n\n605\n10.0\n156.142000\n0.354206\n155.62\n156.0700\n156.080\n156.2075\n156.84\n\n\n655\n11.0\n154.022727\n0.224414\n153.72\n153.8800\n153.920\n154.2400\n154.35\n\n\n705\n9.0\n153.008889\n0.241425\n152.74\n152.8100\n152.910\n153.2700\n153.29\n\n\n\n\n\n\n\n \nHiernach ist die höchste Standardabweichung für die Messreihe mit 301 Gramm zu verzeichnen. Die gemessenen Werte sind jedoch unauffällig.\n\ngewicht = 301\n\nz_values = scipy_z_values = scipy.stats.zscore(hooke[hooke['mass'] == gewicht].loc[: , 'distance'], ddof = 1)\nz_values.name = 'z-values'\n\nprint(pd.concat([hooke[hooke['mass'] == gewicht], z_values], axis = 1))\n\n    no  mass  distance  z-values\n70  70   301    162.38 -0.800734\n71  71   301    161.93 -1.071658\n72  72   301    161.95 -1.059617\n73  73   301    161.60 -1.270337\n74  74   301    164.59  0.529809\n75  75   301    165.86  1.294419\n76  76   301    163.82  0.066226\n77  77   301    163.83  0.072247\n78  78   301    165.57  1.119823\n79  79   301    165.57  1.119823\n\n\nDie Grafik des bereinigten Datensatzes legt einen linearen Zusammenhang nahe. Darüber hinaus sticht der mit zunehmendem Gewicht abfallende Trend der Datenpunkte ins Auge.\n\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = 'bereinigter Datensatz', ylabel = 'Abstand in cm', xlabel = 'Gewicht in Gramm')\n\n\n\n\n\n\n\n\n \nEntsprechend des Versuchsaufbaus nimmt mit zunehmender Dehnung der Feder der Abstand zum Abstandssensor ab. Da die Federausdehnung gemessen werden soll, bietet es sich an, die Daten entsprechend zu transformieren. Dazu wird der gemessene Abstand bei 0 Gramm Gewicht als Nullpunkt aufgefasst, von dem aus die Federdehnung gemessen wird. Das bedeutet, dass von allen Datenpunkten das arithmetische Mittel der für 0 Gramm Gewicht gemessen Ausdehnung abgezogen und das Ergebnis mit -1 multipliziert wird.\n\nnullpunkt = hooke[hooke['mass'] == 0].loc[: , 'distance'].mean()\nprint(f\"Nullpunkt: {nullpunkt:.2f} cm\")\n\nhooke['distance'] = hooke['distance'].sub(nullpunkt).mul(-1)\n\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = 'bereinigter und invertierter Datensatz', ylabel = 'Federausdehnung in cm', xlabel = 'Gewicht in Gramm')\n\nNullpunkt: 173.63 cm\n\n\n\n\n\n\n\n\n\n \nMit der Funktion plt.errorbars() können die Mittelwerte und Standardfehler für jedes Gewicht grafisch dargestellt werden. Da die Standardfehler eher klein sind, werden mit dem Parameter capsize horizontale Linien am Ende des Fehlerbalkens eingezeichnet.\n\n# Mittelwerte nach Gewicht\ndistance_means_by_weight = hooke['distance'].groupby(by = hooke['mass']).mean()\ndistance_means_by_weight.name = 'Federausdehnung'\n\n# Standardfehler nach Gewicht\ndistance_stderrors_by_weight = hooke['distance'].groupby(by = hooke['mass']).std(ddof = 1).div(np.sqrt(hooke['distance'].groupby(by = hooke['mass']).size()))\ndistance_stderrors_by_weight.name = 'Standardfehler'\n\nhooke.plot(x = 'mass', y = 'distance', kind = 'scatter', title = 'bereinigter und invertierter Datensatz', ylabel = 'Federausdehnung in cm', xlabel = 'Gewicht in Gramm', alpha = 0.6)\n\nerrorbar_container = plt.errorbar(\n  x = distance_means_by_weight.index, y = distance_means_by_weight, yerr = distance_stderrors_by_weight,\n  linestyle = 'none', marker = 'x', color = 'black', markersize = 12, elinewidth = 3, ecolor = 'red', capsize = 12)\n\n# siehe: https://matplotlib.org/stable/api/container_api.html#matplotlib.container.ErrorbarContainer\nplt.legend([errorbar_container.lines[0], errorbar_container.lines[2][0]],\n           ['Mittelwert', 'Standardfehler'],\n           loc = 'upper left')\nplt.show()\n\nprint(pd.concat([distance_means_by_weight, distance_stderrors_by_weight], axis = 1))\n\n\n\n\n\n\n\n\n      Federausdehnung  Standardfehler\nmass                                 \n0       -7.751375e-15        0.110778\n100      2.586364e+00        0.297240\n201      5.839091e+00        0.089339\n301      9.920909e+00        0.525247\n401      1.166391e+01        0.099052\n452      1.291791e+01        0.198545\n503      1.431691e+01        0.247005\n554      1.608391e+01        0.165637\n605      1.748891e+01        0.112010\n655      1.960818e+01        0.067663\n705      2.062202e+01        0.080475",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Parameterschätzung</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html#federkonstante-bestimmen",
    "href": "skript/hooke.html#federkonstante-bestimmen",
    "title": "3  Lineare Parameterschätzung",
    "section": "3.2 Federkonstante bestimmen",
    "text": "3.2 Federkonstante bestimmen\nDie Beziehung zwischen der Kraft \\(F\\) und der Längenänderung \\(\\Delta{x}\\) einer Feder mit Federkonstante \\(k\\) wird durch die Gleichung \\(F = k \\times \\Delta{x}\\) beschrieben. Dabei entspricht die Kraft \\(F\\) dem mit der Fallbeschleunigung \\(g\\) multiplizierten Gewicht in Kilogramm \\(m\\). Die Fallbeschleunigung beträgt auf der Erde \\(9,81 \\frac{m}{s^2}\\).\nDeshalb wird im Datensatz das in der Spalte ‘mass’ eingetragene Gewicht in Gramm in die wirkende Kraft umgerechnet. Ebenso wird die gemessene Abstandsänderung in der Spalte ‘distance’ von Zentimeter in Meter umgerechnet.\n\nhooke['mass'] = hooke['mass'].div(1000).mul(9.81)\nhooke.rename(columns = {'mass': 'force'}, inplace = True)\n\nhooke['distance'] = hooke['distance'].div(100)\n\nprint(hooke.head())\n\n   no    force  distance\n0   0  6.91605  0.203409\n1   1  6.91605  0.208909\n2   2  6.91605  0.203609\n3   3  6.91605  0.208209\n4   4  6.91605  0.208609\n\n\nFür die grafische Darstellung des Zusammenhangs \\(F = k \\times \\Delta{x}\\) ist es zweckmäßiger, die Abstandsänderung auf der x-Achse und die wirkende Kraft auf der y-Achse darzustellen.\n\nhooke.plot(x = 'distance', y = 'force', kind = 'scatter', title = 'umgeformter Datensatz', ylabel = 'wirkende Kraft in $N$', xlabel = 'Abstandsänderung in Meter')\n\n\n\n\n\n\n\n\n\nLineare Ausgleichsrechnung\nDie Ausgleichsrechnung (oder auch Parameterschätzung) ist eine Methode, um für eine Messreihe die unbekannten Parameter des zugrundeliegenden physikalischen Modells zu schätzen. Das Ziel besteht darin, eine (in diesem Fall lineare) Funktion zu bestimmen, die bestmöglich an die Messdaten angepasst ist. (Wikipedia)\nEine lineare Funktion wird durch die Konstante \\(\\beta_0\\), den Schnittpunkt mit der y-Achse, und den Steigungskoeffizienten \\(\\beta_1\\) bestimmt.\n\\[\ny = \\beta_0 + \\beta_1 \\times x\n\\]\nIn der Regel liegt kein deterministischer Zusammenhang vor, sondern es treten zufällige Abweichungen auf, die mit dem additiven Fehlerterm ausgedrückt und aus dem Englischen error mit \\(e_i\\) notiert werden. Diese Fehler werden Residuen genannt.\n\\[\ny = \\beta_0 + \\beta_1 \\times x + e_i\n\\]\nZur Bestimmung der Parameter einer linearen Funktion wird die Methode der kleinsten Quadrate verwendet.\nDie Herleitung der Formeln sind viel LaTeX (Skript MB: 73- 74)\nQuelle: Skript MB S. 71-74\n\n\n\n\n\n\nBeispiel 3.1: Methode der kleinsten Quadrate\n\n\n\n\n\nMit der Methode der kleinsten Quadrate soll diejenige Gerade \\(\\hat{y} = \\beta_0 + \\beta_1 \\times x\\) gefunden werden, die die quadrierten Abstände der Vorhersagewerte \\(\\hat{y}\\) von den tatsächlich gemessenen Werten \\(y\\) minimiert. Die Werte \\(y_i - \\hat{y_i}\\) sind die Residuen \\(e_i\\). Es gilt also:\n\\[\n\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2 = \\sum_{i=1}^{N} e_i = \\min\n\\]\nGrafisch kann man sich die Minimierung der quadrierten Abstände so vorstellen.\n\nGrafikCode\n\n\n\n\n\n\n\n\n\n\n\nRegressionskoeffizienten: [ 2.93333333 -0.73333333]\n\n\n\n\n\nx = np.arange(1, 11)\ny = - x.copy() + 4\ny[0] -= 2\ny[2] -= 2\ny[3] += 3\ny[-3] += 5\n\nlm = poly.polyfit(x, y, 1)\nvorhersagewerte = poly.polyval(x, lm)\n\nplt.scatter(x, vorhersagewerte, label = 'Vorhersagewerte', marker = \"^\", color = \"tab:blue\")\nplt.scatter(x, y, label = 'Messwerte', marker = 'o', color = \"tab:orange\")\nplt.axline(xy1 = (0, lm[0]), slope = lm[1], label = \"Regressionsgerade\", color = \"tab:blue\")\ndotted = plt.vlines(x, ymin = vorhersagewerte, ymax = y, alpha = 0.6, ls = 'dotted', label = 'Residuen')\n\nplt.legend()\nplt.show()\n\nprint(\"Regressionskoeffizienten:\", lm)\n\n\n\n\n \nDie eingezeichnete Gerade entspricht der linearen Funktion \\(\\hat{y} = \\beta_0 + \\beta_1 \\times x + e_i\\). Die Dreiecksmarker sind die Vorhersagewerte \\(\\hat{y_i}\\) des linearen Modells für die Werte \\(x_i = np.arange(1, 11)\\). Die tatsächlichen Messwerte \\(y\\) sind mit Kreismarkern markiert. Die Länge der gestrichelten Linien entspricht der Größe der Abweichung zwischen den Mess- und Vorhersagewerten \\(y_i - \\hat{y_i}\\), also den Residuen \\(e_i\\).\nGesucht wird diejenige Gerade, die die Summe der quadrierten Residuen minimiert. Die gesuchten Werte \\(\\beta_0\\) und \\(\\beta_1\\) sind die Kleinst-Quadrate-Schätzer.\n\\[\n\\beta_0 = \\bar{y} - \\beta_1 \\cdot \\bar{x}\n\\]\n\\[\n\\beta_1 = { \\sum_{i=1}^n (x_i- \\bar{x}) \\cdot (y_i - \\bar{y}) \\over \\sum_{i=1}^n (x_i - \\bar{x})^2 }\n\\]\n\n\n\nDie Funktionen dafür stellen sowohl das Paket numpy.polynomial bzw. für Polynomfunktionen dessen Modul numpy.polynomial.polynomial als auch das Modul scipy.stats.linregress bereit. Im Folgenden wird die Berechnung mit NumPy gezeigt und anschließend die Funktionen aus dem Modul SciPy vorgestellt. Die Funktionsweise beider Module ist ähnlich.\n\nNumPy polyfit und polyeval\n\nimport numpy.polynomial.polynomial as poly\n\nZur Schätzung von Funktionsparametern nach der Methode der kleinsten Quadrate wird die Funktion poly.polyfit(x, y, deg) verwendet. x sind die Werte der unabhängigen Variablen, y die Werte der abhängigen Variablen und deg spezifiziert den Grad der gesuchten Polynomfunktion. deg = 1 spezifiziert eine lineare Funktion.\n\n\n\n\n\n\nBeispiel 3.2: polyfit und polyeval erklärt\n\n\n\n\n\n\n# Beispieldaten erzeugen\nx = np.array(list(range(0, 100)))\ny = x ** 2\n\nprint(poly.polyfit(x, y, 1))\n\n[-1617.    99.]\n\n\nDie Funktion gibt die geschätzten Regressionsparameter als NumPy-Array zurück. Die Terme sind aufsteigend angeordnet, d. h. der Achsabschnitt steht an Indexposition 0, der Steigungskoeffizient an Indexposition 1. Die Ausgabe für ein Polynom zweiten Grades würde beispielsweise so aussehen:\n\nprint(poly.polyfit(x, y, 2))\n\n[ 1.62413205e-12 -5.07904010e-14  1.00000000e+00]\n\n\nMit den Regressionskoeffizienten können die Vorhersagewerte der linearen Funktion berechnet werden. Dafür wird die Funktion poly.polyeval(x, c) verwendet. Diese berechnet die Funktionswerte für in x übergebene Wert(e) mit den Funktionsparametern c. Aus der Differenz der gemessenen Werte und der Vorhersagewerte können die Residuen bestimmt werden.\n\n# 'manuelle' Berechnung\nregressions_koeffizienten = poly.polyfit(x, y, 1)\nvorhersagewerte = regressions_koeffizienten[0] + x * regressions_koeffizienten[1]\nresiduen = y - vorhersagewerte\n\n# Berechnung mit polyeval\nlm = poly.polyfit(x, y, 1)\nvorhersagewerte_polyval = poly.polyval(x, lm)\n\nprint(\"Die Ergebnisse stimmen überein:\", np.equal(vorhersagewerte, vorhersagewerte_polyval).all())\nprint(\"\\nAusschnitt der Vorhersagewerte:\", vorhersagewerte[:10])\n\nDie Ergebnisse stimmen überein: True\n\nAusschnitt der Vorhersagewerte: [-1617. -1518. -1419. -1320. -1221. -1122. -1023.  -924.  -825.  -726.]\n\n\nDas Bestimmtheitsmaß \\(R^2\\) gibt an, wie gut die Schätzfunktion an die Daten angepasst ist. Der Wertebereich reicht von 0 bis 1. Ein Wert von 1 bedeutet eine vollständige Anpassung. Für eine einfache lineare Regression mit nur einer erklärenden Variable kann das Bestimmtheitsmaß als Quadrat des Bravais-Pearson-Korrelationskoeffizienten \\(r\\) berechnet werden. Dieser wird mit der Funktion np.corrcoef(x, y) ermittelt (die eine Matrix der Korrelationskoeffizienten ausgibt).\n\nprint(f\"r = {np.corrcoef(x, y)[0, 1]:.2f}\")\nprint(f\"R\\u00b2 = {np.corrcoef(x, y)[0, 1] ** 2:.2f}\")\n\nr = 0.97\nR² = 0.94\n\n\nDie Daten und die geschätzte Gerade können grafisch dargestellt werden.\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(x, y, label = 'Beispieldaten')\nplt.plot(x, vorhersagewerte, label = 'Vorhersagewerte')\nplt.annotate(\"$R^2$ = {:.2f}\".format(np.corrcoef(x, y)[0, 1] ** 2), (max(x) * 0.9, 1))\n\nplt.title(label = 'Beispieldaten und geschätzte Linearfunktion')\nplt.xlabel('x-Werte')\nplt.ylabel('y-Werte')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nNumPy umfasst außerdem die inzwischen veralteten Funktionen np.polyfit(x, y, deg) und np.polyval(p, x).\n\n\n\n\n\n\nBeispiel 3.3: np.polyfit & np.polyval\n\n\n\n\n\nDie Funktionen np.polyfit(x, y, deg) und np.polyval(p, x) funktionieren wie die vorgestellten Funktionen aus dem Modul numpy.polynomial.polynomial. Ein wichtiger Unterschied besteht jedoch darin, dass die Parameter der Funktion polyfit in umgekehrter Reihenfolge ausgegeben werden.\n\nprint(poly.polyfit(x, y, deg = 1))\nprint(np.polyfit(x, y, deg = 1))\n\n[-1617.    99.]\n[   99. -1617.]\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nThis forms part of the old polynomial API. Since version 1.4, the new polynomial API defined in numpy.polynomial is preferred. A summary of the differences can be found in the transition guide.\n\n\nNumPy-Dokumentation\n\n\n\n\nDie Parameter der an die Messwerte angepassten linearen Funktion und das Bestimmtheitsmaß lauten:\n\nprint(poly.polyfit(hooke['distance'], hooke['force'], 1))\n\nprint(f\"r = {np.corrcoef(hooke['distance'], hooke['force'])[0, 1]:.2f}\")\nprint(f\"R\\u00b2 = {np.corrcoef(hooke['distance'], hooke['force'])[0, 1] ** 2:.2f}\")\n\n[ 0.05753159 33.01899551]\nr = 0.99\nR² = 0.99\n\n\nMit den Regressionskoeffizienten können die Vorhersagewerte der linearen Funktion berechnet werden.\n\n# Berechnung mit polyeval\nlm = poly.polyfit(hooke['distance'], hooke['force'], 1)\nvorhersagewerte_hooke = poly.polyval(hooke['distance'], lm)\n\nDie Messreihe und die darauf angepasste lineare Funktion können grafisch dargestellt werden.\nHier mal überlegen: Die lineare Funktion kennt keine Grenzen, aber die gemessene Abstandsänderung kann nicht (sinnvoll) kleiner als Null werden. Grafisch ist plt.axline() ggf. nicht so optimal.\n\n# Platzhalter x & y\nx = hooke['distance']\ny = hooke['force']\n\n# Plot erstellen\nplt.scatter(x, y, label = 'Messdaten')\nplt.axline(xy1 = (0, lm[0]), slope = lm[1], label = 'Regressionsgerade\\ny = ' + \"{beta_0:.3f}\".format(beta_0 = lm[0]) + ' + ' + \"{beta_1:.3f} \".format(beta_1 = lm[1]) + 'x' )\nplt.annotate(\"$R^2$ = {:.2f}\".format(np.corrcoef(x, y)[0, 1] ** 2), (max(x) * 0.9, 1))\n\nplt.title(label = 'Messdaten und geschätzte Linearfunktion')\nplt.xlabel('gemessene Abstandsänderung in m')\nplt.ylabel('wirkende Kraft')\nplt.legend()\n\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nMessabweichung quantifizieren\nFür den geschätzten Regressionskoeffizienten kann für die lineare Regression mit einer erklärenden Variable der Standardfehler des Regressionskoeffizienten \\(SE = \\hat{\\sigma}_{\\hat{\\beta_1}}\\) ermittelt werden (siehe Wikipedia).\n\\[\nSE = \\sqrt{\\frac{\\frac{1}{n-2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{ \\sum_{i=1}^{n} (x_i - \\bar{x})^2}}\n\\]\n\nIm Zähler steht die mittlere Residuenquadratsumme (Summe der quadrierten Residuen / Anzahl der Freiheitsgrade).\nIm Nenner steht die Summe der Abweichungsquadrate von \\(x\\).\n\nFür ein Signifikanzniveau \\(\\alpha\\) kann ein Konfidenzniveau \\(1 - \\alpha\\) angegeben werden als:\n\\[\n\\hat{\\beta_1} \\pm SE \\times t_{1-\\alpha / 2} ~ (n - 2)\n\\]\n\n\\(t_{1-\\alpha / 2} ~ (n - 2)\\) ist der Wert der t-Verteilung mit 2 Freiheitsgraden bzw. der Rückgabewert der Funktion:\n\nscipy.stats.t.ppf(q = 1 - alpha/2, df = n - 2) für die obere Intervallgrenze.\n\n\n\nprint(f\"Regressionskoeffizient: {lm[1]:.4f}\")\n\n# 'manuell' Standardfehler des Regressionskoeffizienten berechnen\nstandardfehler_beta_1 = np.sqrt( (1 / (len(x) - 2) * sum((y - vorhersagewerte_hooke) ** 2)) / sum( (x - x.mean()) ** 2  ))\n\nprint(f\"Standardfehler des Regressionskoeffizienten: {standardfehler_beta_1:.4f}\")\n\n# Signifikanzniveau (alpha-Niveau) 1 - 95 % wählen\nalpha = 0.05\nn = len(x)\n\nt_wert = scipy.stats.t.ppf(q = 1 - alpha/2, df = n - 2)\nprint(f\"t-Wert 95-%-Intervall (zweiseitig): {t_wert:.4f}\")\nprint(f\"Konfidenzintervall 95%: {lm[1]:.4f} ± {t_wert:.4f} * {standardfehler_beta_1:.4f}\")\nprint(f\"untere 95-%-Intervallgrenze: {lm[1] - t_wert * standardfehler_beta_1:.4f}\")\nprint(f\"obere 95-%-Intervallgrenze: {lm[1] + t_wert * standardfehler_beta_1:.4f}\")\n\nRegressionskoeffizient: 33.0190\nStandardfehler des Regressionskoeffizienten: 0.3784\nt-Wert 95-%-Intervall (zweiseitig): 1.9816\nKonfidenzintervall 95%: 33.0190 ± 1.9816 * 0.3784\nuntere 95-%-Intervallgrenze: 32.2692\nobere 95-%-Intervallgrenze: 33.7688\n\n\nDas Konfidenzintervall kann auch grafisch dargestellt werden.\ngeht das nicht einfacher?! Das Konfidenzintervall mit plt.fill_between() endet bei max(x), die Regressionsgerade ist aber kontinuierlich. Man müsste mit np.linspace() x-Werte erzeugen, für diese mit poly.polyval(x, lm[0]) y-Werte erzeugen und plotten. Dabei müssten die Grenzen des Plots aus einem vorherigen plot-Aufruf abgegriffen und fest gesetzt werden.\n\n# Platzhalter x & y\nx = hooke['distance']\ny = hooke['force']\n\n# Plot erstellen\nplt.scatter(x, y, label = 'Messdaten')\nplt.axline(xy1 = (0, lm[0]), slope = lm[1], label = 'Regressionsgerade\\ny = ' + \"{beta_0:.3f}\".format(beta_0 = lm[0]) + ' + ' + \"{beta_1:.3f} \".format(beta_1 = lm[1]) + 'x' )\nplt.annotate(\"$R^2$ = {:.2f}\".format(np.corrcoef(x, y)[0, 1] ** 2), (max(x) * 0.9, 1))\n\n# 95-%-Konfidenzintervall einzeichnen\n## poly.polyval(hooke['distance'], [lm[0]])\nbeta1_lower_boundary = lm[1] - (t_wert * standardfehler_beta_1)\nbeta1_upper_boundary = lm[1] + (t_wert * standardfehler_beta_1)\n\ny_lower_boundary = poly.polyval(hooke['distance'], [lm[0], beta1_lower_boundary])\ny_upper_boundary = poly.polyval(hooke['distance'], [lm[0], beta1_upper_boundary])\n\nplt.fill_between(x = x, y1 = y_lower_boundary , y2 = y_upper_boundary, alpha = 0.3, label = '95-%-Konfidenzintervall $\\\\beta_1$')\n\n\nplt.title(label = 'Messdaten und geschätzte Linearfunktion im 95-%-Intervall')\nplt.xlabel('gemessene Abstandsänderung in m')\nplt.ylabel('wirkende Kraft')\nplt.legend()\n\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nDas Modul SciPy\nDie Funktion scipy.stats.lingress(x, y) liefert mit einem Funktionsaufruf zahlreiche Rückgabewerte:\n\nSteigung der Regressionsgerade,\ny-Achsenschnittpunkt der Regressionsgerade,\nBravais-Pearson-Korrelationskoeffizient r,\np-Wert der Nullhypothese, dass die Steigung der Regressionsgerade Null ist,\nStandardfehler der Steigung und\nStandardfehler des y-Achsenschnittpunkts.\n\nDer Standardfehler des y-Achsenschnittpunkts ist nur verfügbar, wenn die Rückgabewerte in einem Objekt gespeichert werden. Die Rückgabewerte können dann als Attribute abgerufen werden.\n\n# Zuweisung mehrerer Objekte\nslope, intercept, rvalue, pvalue, slope_stderr = scipy.stats.linregress(x, y)\nprint(f\"y = {intercept:.4f} + {slope:.4f} * x\\n\",\n      f\"r = {rvalue:.4f} R2 = {rvalue ** 2:.4f} p = {pvalue:.4f}\\n\",\n      f\"Standardfehler des Anstiegs: {slope_stderr:.4f}\", sep = '')\n\n# Zuweisung eines Objekts\nlm = scipy.stats.linregress(x, y)\n\nprint(\"\\n\", lm, sep = '')\nprint(f\"y-Achsenschnittpunkt: {lm.intercept:.4f}\\nStandardfehler des y-Achsenschnittpunkts:{lm.intercept_stderr:.4f}\")\n\ny = 0.0575 + 33.0190 * x\nr = 0.9928 R2 = 0.9856 p = 0.0000\nStandardfehler des Anstiegs: 0.3784\n\nLinregressResult(slope=np.float64(33.01899550918018), intercept=np.float64(0.05753158907970102), rvalue=np.float64(0.9927907555799099), pvalue=np.float64(4.115211719827619e-104), stderr=np.float64(0.37837320019327897), intercept_stderr=np.float64(0.0506707972676925))\ny-Achsenschnittpunkt: 0.0575\nStandardfehler des y-Achsenschnittpunkts:0.0507\n\n\nSo kann mit dem entsprechenden t-Wert das Konfidenzintervall berechnet werden.\n\nalpha = 0.05\nn = len(x)\n\nprint(f\"{slope - scipy.stats.t.ppf(q = 1 - alpha / 2, df = n - 2) * slope_stderr:.3f}  ≤ {slope:.3f} ≤ {slope + scipy.stats.t.ppf(q = 1 - alpha / 2, df = n - 2) * slope_stderr:.3f}\")\n\n32.269  ≤ 33.019 ≤ 33.769\n\n\n\n\nErgebnis Federkonstante\nDie Federkonstante des Versuchaufbaus liegt mit 95 prozentiger Sicherheit im Intervall zwischen 32.27 und 33.77. Die Punktschätzung für die Federkonstante beträgt 33.02.\nAufgabe könnte sein, das Konfidenzintervall 99-Prozent zu berechnen.\n–&gt; Dann muss man aber nur eine Zahl ändern",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Parameterschätzung</span>"
    ]
  },
  {
    "objectID": "skript/hooke.html#resterampe---größtfehler",
    "href": "skript/hooke.html#resterampe---größtfehler",
    "title": "3  Lineare Parameterschätzung",
    "section": "3.3 Resterampe - Größtfehler?!",
    "text": "3.3 Resterampe - Größtfehler?!\nSiehe Musterbericht WA S. 12-13\nDer Größtfehler quantifiziert den ungünstigsten Fall, bei dem sich alle möglichen Fehlerquellen addieren.\n\ngrobe Fehler: falscher Versuchsaufbau, ungeeignete Messgeräte, falsches Ablesen, Unachtsamkeit –&gt; betroffene Werte streichen und Messung Wiederholen\n\nDer Größtfehler \\(\\Delta x\\) setzt sich zusammen aus dem systematischen Fehler und dem zufälligen Fehler.\n\nsystematische Fehler: Fehler der Messgeräte, der Art der Messung (bspw. Genauigkeit Abstandssenor)\n\ndas ist die Küchenwaage, deren systematischer Fehler auf \\(\\frac{g}{\\Delta x} = \\frac{9.81}{\\Delta x}\\) ? Was ist Delta-x, die Ausdehnung?!\n\nDie Masse wäre 705g –&gt; müsste die Messungenauigkeit der Küchenwaage mit 0.5 g nicht ins Verhältnis zu 705 g gesetzt werden?\n\n\nzufällige Fehler: Streuung von Messwerten um Erwartungswert –&gt; statistischer Charakter der Fehler\n\nDurch Umstellen nach der Federkonstante \\(k\\) kann diese wie folgt ermittelt werden:\n\\[\nk = \\frac{m \\times g}{\\Delta{x}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Parameterschätzung</span>"
    ]
  },
  {
    "objectID": "skript/hooke2.html",
    "href": "skript/hooke2.html",
    "title": "4  Anwendung Hooke’sches Gesetz",
    "section": "",
    "text": "Das ganze Kapitel ist eine geführte Aufgabe mit Lösungen\n“Das Ergebnis könnte so aussehen.”\nWir können ja fragen: Liegen gültige Messungen vor? Wurden die Messungen mit der selben Feder durchgeführt?\nDafür wäre die Einführung der Fehlerrechnung bzw. des Größtfehlers sinnvoll, weil hier auf das Vorliegen grober Fehler geprüft werden kann / soll.\nHäufig liegen Sensordaten in mehreren Dateien vor. Mögliche Gründe dafür können sein, dass die Messung\n\nvon unterschiedlichen Personen,\nan unterschiedlichen Standorten,\nzu unterschiedlichen Zeiten oder\nfür unterschiedliche Messgrößen durchgeführt wurden.\n\nIm Ordner ‘aufgaben/01-daten/hooke’ liegen mehrere txt-Dateien mit Messdaten\nWir prüfen ‘automatisiert’, ob mehrere Datensätze Fehlmessungen enthalten. Anschließend bestimmen wir die Federkonstanten und die Konfidenzintervalle.\n\neinlesen mit glob - aufgaben/01-daten\nz-Werte (studentisiert) nach Gewicht bestimmen\nFederkonstante im Konfidenzintervall ausgeben",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Anwendung Hooke'sches Gesetz</span>"
    ]
  }
]